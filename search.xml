<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>JVM</title>
      <link href="/2023/03/17/jvm/"/>
      <url>/2023/03/17/jvm/</url>
      
        <content type="html"><![CDATA[<h2 id="JVM整体架构"><a href="#JVM整体架构" class="headerlink" title="JVM整体架构"></a>JVM整体架构</h2><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212052.png" alt="image-20220717105453271"></p><h2 id="Java-内存区域"><a href="#Java-内存区域" class="headerlink" title="Java 内存区域"></a>Java 内存区域</h2><blockquote><p>常见面试题 ：</p><ul><li>介绍下 Java 内存区域（运行时数据区）</li><li>Java 对象的创建过程（五步，建议能默写出来并且要知道每一步虚拟机做了什么）</li><li>对象的访问定位的两种方式（句柄和直接指针两种方式）</li></ul></blockquote><p>Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212056.png" alt="image-20220717173800326">-</p><p><strong>JDK 1.8 之前</strong> ：</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212058.png" alt="image-20220717105748131" style="zoom: 80%;" /> <p><strong>JDK 1.8</strong> ：</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212101.png" alt="image-20220717105803889" style="zoom:80%;" /> <p><strong>线程私有的：</strong></p><ul><li>程序计数器</li><li>虚拟机栈</li><li>本地方法栈</li></ul><p><strong>线程共享的：</strong></p><ul><li>堆</li><li>方法区</li><li>直接内存 (非运行时数据区的一部分)</li></ul><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><blockquote><p><strong>特点</strong></p><ul><li>线程私有，每条线程都有一个独立的程序计数器，用于记录当前线程执行的位置</li><li>唯一一个不会出现 <code>OutOfMemoryError</code> 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。</li></ul></blockquote><p>程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令</p><p>如果线程执行java方法，计数器记录的是正在执行的虚拟机字节码指令的地址，如果执行的是本地（Native）方法，计数器值为空（Undefined）。</p><h4 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h4><blockquote><p><strong>特点</strong></p><ul><li>线程私有</li><li>生命周期随着线程的创建而创建，随着线程的结束而死亡。</li></ul></blockquote><p>每个线程运行需要的内存空间，称为虚拟机栈，每个栈由多个栈帧组成，对应着每次调用方法时所占用的内存，每个线程只能有一个活动栈帧，对应着当前正在执行的方法</p><p>每一次方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p><p>每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212105.png" alt="image-20220717111104156"> </p><ul><li><p><strong>局部变量表</strong> 主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。</p></li><li><p><strong>操作数栈</strong> 主要作为方法调用的中转站使用，用于存放方法执行过程中产生的中间计算结果。另外，计算过程中产生的临时变量也会放在操作数栈中。</p></li><li><p><strong>动态链接</strong> 主要服务一个方法需要调用其他方法的场景。在 Java 源文件被编译成字节码文件时，所有的变量和方法引用都作为符号引用（Symbilic Reference）保存在 Class 文件的常量池里。当一个方法要调用其他方法，需要将常量池中指向方法的符号引用转化为其在内存地址中的直接引用。动态链接的作用就是为了将符号引用转换为调用方法的直接引用。</p></li></ul><p>程序运行中栈可能会出现两种错误：</p><ul><li><p><code>StackOverFlowError</code>：若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 <code>StackOverFlowError</code> 错误。（方法递归）</p></li><li><p><code>OutOfMemoryError</code>： 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出<code>OutOfMemoryError</code>异常。</p></li></ul><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><p>虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。</p><p>本地方法带native关键字，通常由C或C++实现，与操作系统底层交互。</p><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><blockquote><p><strong>特点</strong></p><ul><li>线程共享</li><li>虚拟机启动时创建</li></ul></blockquote><p>Java 虚拟机所管理的内存中最大的一块，此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。</p><p>Java 堆是垃圾收集器管理的主要区域，因此也被称作 GC 堆（Garbage Collected Heap），<strong>从垃圾回收的角度</strong>，Java 堆还可以细分为：新生代和老年代。</p><p>下图所示的 Eden 区、两个 Survivor 区 S0 和 S1 都属于新生代，中间一层属于老年代，最下面一层属于永久代。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212110.png" alt="image-20220717161542193"> </p><p>堆这里最容易出现的就是<code>OutOfMemoryError</code> 错误：</p><ol><li><code>java.lang.OutOfMemoryError: GC Overhead Limit Exceeded</code>： 当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。</li><li><code>java.lang.OutOfMemoryError: Java heap space</code> :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。(和配置的最大堆内存有关，且受制于物理内存大小。最大堆内存可通过<code>-Xmx</code>参数配置}</li></ol><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><blockquote><p><strong>特点</strong></p><ul><li>线程共享</li><li>虚拟机启动时创建</li></ul></blockquote><p>当虚拟机要使用一个类时，它需要读取并解析 Class 文件获取相关信息，再将信息存入到方法区。方法区会存储已被虚拟机加载的 <strong>类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据</strong>。</p><p>方法区是一个 JVM 规范，<strong>永久代与元空间都是其一种实现方式</strong></p><p>JDK6之前方法区的实现是永久代，在JDK7已经把原本放在永久代中的字符常量池、静态变量等移到Java堆中；在JDK8时将永久代剩余内容（主要是类加载信息，包括类的方法、参数、接口以及常量池表）全部移到元空间，并删除永久代，则方法区实现变成了元空间。元空间使用的内存叫做 本地内存 （主要是区别于堆内存）。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212113.png" alt="image-20220717175018133"> </p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212116.png" alt="image-20220717175034204"> </p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212118.png" alt="image-20220717175049911"> </p><p>当元空间溢出时会得到如下错误： <code>java.lang.OutOfMemoryError: MetaSpace</code></p><h4 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h4><p>Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）的 <strong>常量池表(Constant Pool Table)</strong> 。</p><p>字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量，符号引用包括类符号引用、字段符号引用、方法符号引用和接口方法符号引用。</p><p>常量池表会在类加载后存放到方法区的运行时常量池中，运行期间也可以将析的常量放入池中，例如 String 类的 intern()</p><p>运行时常量池的功能类似于传统编程语言的符号表，尽管它包含了比典型符号表更广泛的数据。</p><p>既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 <code>OutOfMemoryError</code> 错误</p><h4 id="字符串常量池"><a href="#字符串常量池" class="headerlink" title="字符串常量池"></a>字符串常量池</h4><p><strong>字符串常量池</strong> 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建</p><p>HotSpot 虚拟机中字符串常量池的实现是 <code>src/hotspot/share/classfile/stringTable.cpp</code> ,<code>StringTable</code> 本质上就是一个<code>HashSet&lt;String&gt;</code> ,容量为 <code>StringTableSize</code>（可以通过 <code>-XX:StringTableSize</code> 参数来设置）。</p><p>JDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中。</p><blockquote><p>JDK 1.7 为什么要将字符串常量池移动到堆中？</p><p>主要是因为永久代（方法区实现）的 GC 回收效率太低，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时地回收字符串内存。</p></blockquote><p>**<code>StringTable</code> **</p><p>在 JDK 6 及以前版本，字符串常量池保存字符串对象；JDK 6 之后的版本中，既保存了字符串对象，又保存了字符串对象的引用。</p><ul><li>直接使用双引号声明出来的<code>String</code>对象会直接存储在常量池中。</li><li>如果不是用双引号声明的<code>String</code>对象，存储在Java堆中。</li></ul><pre class=" language-java"><code class="language-java">String s <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token string">"abc"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//创建了2个对象，</span><span class="token comment" spellcheck="true">//一个是字符串字面量"xyz"所对应的、驻留（intern）在一个全局共享的字符串常量池中的实例，</span><span class="token comment" spellcheck="true">//另一个是通过new String(String)创建并初始化的、内容与"xyz"相同的实例</span></code></pre><blockquote><p>R大的回答： <a href="https://www.iteye.com/topic/774673">String s = <strong>new</strong> String(“xyz”)创键了几个String实例</a>  </p></blockquote><blockquote><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>字符串常量池中是对象引用还是对象实例？</p><p>对象引用</p><p><a href="https://www.zhihu.com/question/55994121/answer/147296098">Java 中new String(“字面量”) 中 “字面量” 是何时进入字符串常量池的?</a></p><p><a href="https://zhuanlan.zhihu.com/p/405163001">深入String分析（包含字符串常量池底层实现）</a></p><p>对象实例</p><p><a href="https://zhuanlan.zhihu.com/p/130929194">一个提问引起的“厮杀”，到底什么是Java字符串常量池</a></p></blockquote><p><strong>字符串拼接</strong></p><ul><li>字符串变量拼接的原理是StringBuild，</li><li>字符串常量拼接的原理是编译器优化</li></ul><pre class=" language-java"><code class="language-java">String a <span class="token operator">=</span> <span class="token string">"a"</span><span class="token punctuation">;</span>String b <span class="token operator">=</span> <span class="token string">"b"</span><span class="token punctuation">;</span>String ab1 <span class="token operator">=</span> a<span class="token operator">+</span>b<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//StringBuilder().append(“a”).append(“b”).toString(),回的一个String对象，存在于堆内存之中</span>String ab2 <span class="token operator">=</span> <span class="token string">"a"</span> <span class="token operator">+</span> <span class="token string">"b"</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//，因为内容是常量，javac在编译期会进行优化，结果已在编译期确定为ab,可以理解为String ab2 = "ab";</span></code></pre><p><strong><code>String#intern</code> 方法</strong></p><ul><li>在 JDK 6 中，当调用字符串的 <code>intern()</code> 时，若字符串常量池先前已创建出该字符串对象，则返回字符串常量池中该字符串对象的引用。否则，将该字符串对象添加到字符串常量池中，再返回该字符串对象的引用。</li><li>而在 JDK 7 中，当调用 <code>intern()</code> 时，如果字符串常量池先前已创建出该字符串对象，则返回池中的该字符串的引用。否则，若该字符串对象已经存在于 Java 堆中，则将<strong>堆中对此对象的引用</strong>添加到字符串常量池中，然后返回该引用；如果堆中不存在，则在池中创建该字符串并返回其引用。</li></ul><pre class=" language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    String s <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s<span class="token punctuation">.</span><span class="token function">intern</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    String s2 <span class="token operator">=</span> <span class="token string">"1"</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>s <span class="token operator">==</span> s2<span class="token punctuation">)</span><span class="token punctuation">;</span>    String s3 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s3<span class="token punctuation">.</span><span class="token function">intern</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    String s4 <span class="token operator">=</span> <span class="token string">"11"</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>s3 <span class="token operator">==</span> s4<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//打印结果是：</span><span class="token comment" spellcheck="true">//  jdk6 下false false</span><span class="token comment" spellcheck="true">//  jdk7 下false true</span></code></pre><blockquote><p><a href="https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html">深入解析String#intern</a></p></blockquote><blockquote><h4 id="运行时常量池、方法区、字符串常量池这些都是不随虚拟机实现而改变的逻辑概念，是公共且抽象的，Metaspace、Heap-是与具体某种虚拟机实现相关的物理概念，是私有且具体的。"><a href="#运行时常量池、方法区、字符串常量池这些都是不随虚拟机实现而改变的逻辑概念，是公共且抽象的，Metaspace、Heap-是与具体某种虚拟机实现相关的物理概念，是私有且具体的。" class="headerlink" title="运行时常量池、方法区、字符串常量池这些都是不随虚拟机实现而改变的逻辑概念，是公共且抽象的，Metaspace、Heap 是与具体某种虚拟机实现相关的物理概念，是私有且具体的。"></a>运行时常量池、方法区、字符串常量池这些都是不随虚拟机实现而改变的逻辑概念，是公共且抽象的，Metaspace、Heap 是与具体某种虚拟机实现相关的物理概念，是私有且具体的。</h4></blockquote><h4 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h4><p>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域</p><p>JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。</p><h3 id="HotSpot-虚拟机对象探秘"><a href="#HotSpot-虚拟机对象探秘" class="headerlink" title="HotSpot 虚拟机对象探秘"></a>HotSpot 虚拟机对象探秘</h3><p>HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。</p><h4 id="对象创建"><a href="#对象创建" class="headerlink" title="对象创建"></a>对象创建</h4><h5 id="类加载检查"><a href="#类加载检查" class="headerlink" title="类加载检查"></a>类加载检查</h5><p>虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。</p><h5 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h5><p>在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方法有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定**。</p><p>内存分配的两种方式 ：</p><ul><li>指针碰撞 ：<ul><li>适用场合 ：堆内存规整（即没有内存碎片）的情况下。</li><li>原理 ：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。</li><li>使用该分配方式的 GC 收集器：Serial, ParNew</li></ul></li><li>空闲列表 ：<ul><li>适用场合 ： 堆内存不规整的情况下。</li><li>原理 ：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。</li><li>使用该分配方式的 GC 收集器：CMS</li></ul></li></ul><p>选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的。</p><p>内存分配并发问题（补充内容，需要掌握）</p><p>在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：</p><ul><li>CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。</li><li>TLAB：为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配</li></ul><h5 id="初始化零值"><a href="#初始化零值" class="headerlink" title="初始化零值"></a>初始化零值</h5><p>内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。</p><h5 id="设置对象头"><a href="#设置对象头" class="headerlink" title="设置对象头"></a>设置对象头</h5><p>初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。</p><h5 id="执行-init-方法"><a href="#执行-init-方法" class="headerlink" title="执行 init 方法"></a>执行 init 方法</h5><p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，<code>&lt;init&gt;</code> 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <code>&lt;init&gt;</code> 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</p><h4 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h4><p>在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头<strong>、</strong>实例数据和对齐填充。</p><p>Hotspot 虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p><p>实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。</p><p>对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。</p><h4 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h4><p>建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：使用句柄、直接指针。</p><h5 id="句柄"><a href="#句柄" class="headerlink" title="句柄"></a>句柄</h5><p>如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212128.png" alt="image-20220718214345127"></p><h5 id="直接指针"><a href="#直接指针" class="headerlink" title="直接指针"></a>直接指针</h5><p>如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212132.png" alt="image-20220718214247616"></p><p>这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。</p><p>HotSpot 虚拟机主要使用的就是第二种方式来进行对象访问。</p><h2 id="JVM-垃圾回收"><a href="#JVM-垃圾回收" class="headerlink" title="JVM 垃圾回收"></a>JVM 垃圾回收</h2><blockquote><p>常见面试题 ：</p><ul><li>如何判断对象是否死亡（两种方法）。</li><li>简单的介绍一下强引用、软引用、弱引用、虚引用（虚引用与软引用和弱引用的区别、使用软引用能带来的好处）。</li><li>如何判断一个常量是废弃常量</li><li>如何判断一个类是无用的类</li><li>垃圾收集有哪些算法，各自的特点？</li><li>HotSpot 为什么要分为新生代和老年代？</li><li>常见的垃圾回收器有哪些？</li><li>介绍一下 CMS,G1 收集器。</li><li>Minor Gc 和 Full GC 有什么不同呢？</li></ul></blockquote><h3 id="死亡对象判断方法"><a href="#死亡对象判断方法" class="headerlink" title="死亡对象判断方法"></a>死亡对象判断方法</h3><p>堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断哪些对象已经死亡（即不能再被任何途径使用的对象）。</p><h4 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h4><p>给对象中添加一个引用计数器：</p><ul><li>每当有一个地方引用它，计数器就加 1；</li><li>当引用失效，计数器就减 1；</li><li>任何时候计数器为 0 的对象就是不可能再被使用的。</li></ul><p>这个方法实现简单，效率高，但在java领域，主流的java虚拟机都没有选用引用计数法来管理内存，主要原因是这个算法有很多例外情况需要考虑，必须配合大量额外处理才能保证正确工作，如对象之间相互循环引用的问题。</p><p>如下面代码所示：除了对象 <code>objA</code> 和 <code>objB</code> 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。</p><pre class=" language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ReferenceCountingGc</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    Object instance <span class="token operator">=</span> null<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        ReferenceCountingGc objA <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ReferenceCountingGc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        ReferenceCountingGc objB <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ReferenceCountingGc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        objA<span class="token punctuation">.</span>instance <span class="token operator">=</span> objB<span class="token punctuation">;</span>        objB<span class="token punctuation">.</span>instance <span class="token operator">=</span> objA<span class="token punctuation">;</span>        objA <span class="token operator">=</span> null<span class="token punctuation">;</span>        objB <span class="token operator">=</span> null<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><h4 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h4><p>这个算法的基本思想就是通过一系列的称为 <strong>“GC Roots”</strong> 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212135.png" alt="image-20220724164404917" style="zoom:50%;" /> <p> GC Roots对象包括</p><ul><li>虚拟机栈(栈帧中的本地变量表)中引用的对象，譬当前正在运行的方法所使用到的参数、局部变量、临时变量等。</li><li>本地方法栈(Native 方法)中引用的对象</li><li>方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量。</li><li>方法区中常量引用的对象，譬如字符串常量池(String Table)里的引用</li><li>所有被同步锁(synchronized关键字)持有的对象</li></ul><h5 id="三色标记法"><a href="#三色标记法" class="headerlink" title="三色标记法"></a>三色标记法</h5><h6 id="标记算法"><a href="#标记算法" class="headerlink" title="标记算法"></a>标记算法</h6><p>三色标记法把遍历对象图过程中遇到的对象，标记成以下三种颜色：</p><ul><li>白色：尚未访问过</li><li>灰色：本对象已访问过，但是本对象引用到的其他对象尚未全部访问</li><li>黑色：本对象已访问过，而且本对象引用到的其他对象也全部访问完成</li></ul><p>当 Stop The World (STW) 时，对象间的引用是不会发生变化的，可以轻松完成标记，遍历访问过程为：</p><ol><li>初始时，所有对象都在白色集合</li><li>将 GC Roots 直接引用到的对象挪到灰色集合</li><li>从灰色集合中获取对象：<ul><li>将本对象引用到的其他对象全部挪到灰色集合中</li><li>将本对象挪到黑色集合里面</li></ul></li><li>重复步骤 3，直至灰色集合为空时结束</li><li>结束后，仍在白色集合的对象即为 GC Roots 不可达，可以进行回收</li></ol><p><a href="https://camo.githubusercontent.com/cf25e1aaf22653baab692ba5b79df469bf466c38940b1b685dd5d2be8df583e5/68747470733a2f2f7365617a65616e2e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f696d672f4a6176612f4a564d2de4b889e889b2e6a087e8aeb0e6b395e8bf87e7a88b2e676966"><img src="https://camo.githubusercontent.com/cf25e1aaf22653baab692ba5b79df469bf466c38940b1b685dd5d2be8df583e5/68747470733a2f2f7365617a65616e2e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f696d672f4a6176612f4a564d2de4b889e889b2e6a087e8aeb0e6b395e8bf87e7a88b2e676966" alt="img"></a></p><p>参考文章：<a href="https://www.jianshu.com/p/12544c0ad5c1">https://www.jianshu.com/p/12544c0ad5c1</a></p><hr><h6 id="并发标记"><a href="#并发标记" class="headerlink" title="并发标记"></a>并发标记</h6><p>并发标记时，对象间的引用可能发生变化，多标和漏标的情况就有可能发生</p><p><strong>多标情况</strong>：当 E 变为灰色或黑色时，其他线程断开的 D 对 E 的引用，导致这部分对象仍会被标记为存活，本轮 GC 不会回收这部分内存，这部分本应该回收但是没有回收到的内存，被称之为浮动垃圾</p><ul><li>针对并发标记开始后的新对象，通常的做法是直接全部当成黑色，也算浮动垃圾</li><li>浮动垃圾并不会影响应用程序的正确性，只是需要等到下一轮垃圾回收中才被清除</li></ul><p><a href="https://camo.githubusercontent.com/84264733fdb492ef4166375b54d64c6ea84940e69f59a370abcbb8fd87581278/68747470733a2f2f7365617a65616e2e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f696d672f4a6176612f4a564d2de4b889e889b2e6a087e8aeb0e6b395e5a49ae6a087e68385e586b52e706e67"><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212142" alt="img"></a></p><p><strong>漏标情况：</strong></p><ul><li>条件一：灰色对象断开了对一个白色对象的引用（直接或间接），即灰色对象原成员变量的引用发生了变化</li><li>条件二：其他线程中修改了黑色对象，插入了一条或多条对该白色对象的新引用</li><li>结果：导致该白色对象当作垃圾被 GC，影响到了程序的正确性</li></ul><p>代码角度解释漏标：</p><pre><code>Object G = objE.fieldG; // 读objE.fieldG = null;      // 写objD.fieldG = G;         // 写</code></pre><p>为了解决问题，可以操作上面三步，<strong>将对象 G 记录起来，然后作为灰色对象再进行遍历</strong>，比如放到一个特定的集合，等初始的 GC Roots 遍历完（并发标记），再遍历该集合（重新标记）</p><blockquote><p>所以<strong>重新标记需要 STW</strong>，应用程序一直在运行，该集合可能会一直增加新的对象，导致永远都运行不完</p></blockquote><p>解决方法：添加读写屏障，读屏障拦截第一步，写屏障拦截第二三步，在读写前后进行一些后置处理：</p><ul><li><p><strong>写屏障 + 增量更新</strong>：黑色对象新增引用，会将黑色对象变成灰色对象，最后对该节点重新扫描</p><p>增量更新 (Incremental Update) 破坏了条件二，从而保证了不会漏标</p><p>缺点：对黑色变灰的对象重新扫描所有引用，比较耗费时间</p></li><li><p><strong>写屏障 (Store Barrier) + SATB</strong>：当原来成员变量的引用发生变化之前，记录下原来的引用对象</p><p>保留 GC 开始时的对象图，即原始快照 SATB，当 GC Roots 确定后，对象图就已经确定，那后续的标记也应该是按照这个时刻的对象图走，如果期间对白色对象有了新的引用会记录下来，并且将白色对象变灰（说明可达了，并且原始快照中本来就应该是灰色对象），最后重新扫描该对象的引用关系</p><p>SATB (Snapshot At The Beginning) 破坏了条件一，从而保证了不会漏标</p></li><li><p>**读屏障 (Load Barrier)**：破坏条件二，黑色对象引用白色对象的前提是获取到该对象，此时读屏障发挥作用</p></li></ul><p>以 Java HotSpot VM 为例，其并发标记时对漏标的处理方案如下：</p><ul><li>CMS：写屏障 + 增量更新</li><li>G1：写屏障 + SATB</li><li>ZGC：读屏障</li></ul><h4 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h4><blockquote><p><a href="https://xie.infoq.cn/article/a01eee563cd3d7e107f961e47">深入理解 JVM 垃圾回收机制 - 引用类型</a></p></blockquote><p>JDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。</p><p>JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱）</p><ul><li><p>强引用（StrongReference）</p><p>最常见的普通对象引用，类似<code>Object obj = new Object()</code>这类的引用，<code>obj</code>即为强引用，只要还有强引用指向一个对象，垃圾收集器永远不会回收这个对象。</p></li><li><p>软引用（SoftReference）</p><p>软引用一般用于描述一些有用但非必需的对象。当 JVM 认为内存不足时，才会去尝试回收软引用指向的对象，如果回收以后，还没有足够的内存，才会抛出内存溢出错误。因此，JVM 会确保在抛出内存溢出错误之前，回收软引用指向的对象。软引用通常用来实现内存敏感的缓存</p><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 强引用</span> SoftRefObject obj <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SoftRefObject</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 创建一个软引用指向SoftRefObject类型的实例对象'obj'</span>SoftReference<span class="token operator">&lt;</span>SoftRefObject<span class="token operator">></span> softRef <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SoftReference</span><span class="token operator">&lt;</span>SoftRefObject<span class="token operator">></span><span class="token punctuation">(</span>obj<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//使对象只被软引用关联</span>obj <span class="token operator">=</span> null<span class="token punctuation">;</span>  </code></pre><p>首先创建一个强引用<code>obj</code>指向堆中一个<code>SoftRefObject</code>实例对象，然后我们创建一个软引用，软引用中的<code>referent</code>指向堆中的<code>SoftRefObject</code>实例。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212150.png" alt="image-20220725131822565"> </p></li><li><p>弱引用（WeakReference）</p><p>弱引用的强度比软引用更弱一些，当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。它一般用于维护一种非强制的映射关系，如果获取的对象还在，就是用它，否则就重新实例化，因此，很多缓存框架均基于它来实现。可以用<code>WeakReference</code>类实现弱引用。</p></li><li><p>虚引用（PhantomReference）</p><p>虚引用也被称为幽灵引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。可以用<code>PhantomReference</code>类实现弱引用。</p><p>那虚引用到底有什么作用？其实虚引用主要被用来跟踪对象被垃圾回收的状态，当目标对象被回收之前，它的引用会被放入一个 ReferenceQueue 对象中，通过查看引用队列中是否包含对象所对应的虚引用来判断它是否即将被垃圾回收，从而采取行动。因此，</p></li></ul><h4 id="回收方法区"><a href="#回收方法区" class="headerlink" title="回收方法区"></a>回收方法区</h4><p>方法区的垃圾收集主要回收两部分内容：废弃的常量和不在使用的类型。</p><p>如何判断一个常量是废弃常量？</p><p>假如在字符串常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池了。</p><p>如何判断一个类是无用的类？</p><ul><li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li><li>加载该类的 <code>ClassLoader</code> 已经被回收。</li><li>该类对应的 <code>java.lang.Class</code> 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li></ul><p>虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。</p><h3 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h3><h4 id="分代收集理论"><a href="#分代收集理论" class="headerlink" title="分代收集理论"></a>分代收集理论</h4><p>分代收集理论基于三条经验法则，符合大多数程序运行实际情况：</p><ul><li><p>弱分代假说：绝大多数对象都是朝生夕灭的</p></li><li><p>强分代假说：熬过越多次垃圾收集过程的对象就越难以消亡</p></li><li><p>跨代引用假说：跨代引用相对于同代引用来说仅占极少数</p></li></ul><p>这三个分代假说共同奠定了多款常用的垃圾收集器的一致的设计原则：收集器应该将Java堆划分出不同的区域，然后将回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数）分配到不同的区域之中存储。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212153.png" alt="image-20220725142235773" style="zoom:80%;" /> <ul><li><p>新生代：分为Eden区以及两个survival 区–From区和to区，默认的情况下它们的内存大小比例是8:1:1。</p></li><li><p>老年代：是一个整块区域Tenured区，新生代和老年代的内存比例默认是1：2。</p></li></ul><p>垃圾回收类型分为：</p><ul><li>部分收集（Partial GC）：指目标不是完整收集整个Java堆的垃圾收集，其中又分为：<ul><li>新生代收集（Minor GC/Young GC）：指目标只是新生代的垃圾收集。</li><li>老年代收集（Major GC/Old GC）：指目标只是老年代的垃圾收集。目前只有CMS收集器会有单独收集老年代的行为。</li><li>混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收集。目前只有G1收集器会有这种行为。</li></ul></li><li>整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。</li></ul><blockquote><h4 id="在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。"><a href="#在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。" class="headerlink" title="在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。"></a>在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。</h4></blockquote><h4 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h4><p>该算法分为“标记”和“清除”阶段：标记存活的对象，统一回收所有未被标记的对象·。</p><ul><li>标记: Collector从引用根结点开始遍历,标记所有被引用的对象。一般是在对象的Header中记录为可达对象。</li><li>清除: Collector对堆内存从头到尾进行线性的遍历,如果发现某个对象在其Header中没有标记为可达对象,则将其回收，把分块连接到空闲列表的单向链表</li></ul><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212157.png" alt="image-20220726173845302" style="zoom:67%;" /> <p>算法缺点：</p><ul><li>​                                                                                               </li></ul><h4 id="标记-复制算法"><a href="#标记-复制算法" class="headerlink" title="标记-复制算法"></a>标记-复制算法</h4><blockquote><p>为解决标记—清除算法面对大量可回收对象时执行效率低的问题</p></blockquote><p>标记-复制算法将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212159.png" alt="image-20220726204805749" style="zoom: 67%;" /><p>现在的商用java虚拟机大多都优先采用这种收集算法去回收新生代，HotSpot虚拟机的Serial、ParNew等新生代收集器均采用了Appel式回收策略来设计新生代的内存布局：</p><p>Appel式回收的具体做法是把新生代分为一块较大的Eden空间和两块较小的Survivor空间，每次分配内存只使用Eden和其中一块Survivor。发生垃圾收集时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1。</p><p>Appel式回收还有一个充当罕见情况的“逃生门”的安全设计，当Survivor空间不足以容纳一次Minor GC之后存活的对象时，就需要依赖其他内存区域（实际上大多就是老年代）进行分配担保（Handle Promotion）。</p><h4 id="标记—整理算法"><a href="#标记—整理算法" class="headerlink" title="标记—整理算法"></a>标记—整理算法</h4><blockquote><p>标记-复制算法在对象存活率较高时就要进行较多的复制操作，效率将会降低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。</p></blockquote><p>根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212204.png" alt="image-20220726215020926" style="zoom:67%;" /><h3 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h3><blockquote><h4 id="垃圾收集器前置知识：HotSpot的算法细节实现"><a href="#垃圾收集器前置知识：HotSpot的算法细节实现" class="headerlink" title="垃圾收集器前置知识：HotSpot的算法细节实现"></a>垃圾收集器前置知识：<a href="https://juejin.cn/post/6844904090254704653">HotSpot的算法细节实现</a></h4></blockquote><blockquote><p>垃圾收集算法是内存回收的方法论，垃圾收集器是内存回收的具体实现。</p></blockquote><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212207.png" alt="image-20220726223519997"></p><p>上图中的五个垃圾收集器分为以下三大类：</p><ol><li>Serial 类：新生代版本为 Serial，老年代版本为 Serial Old，这两个都是单线程垃圾收集器。另外，ParNew 相比 Serial 只是增加了多线程并行收集的功能，并无其他太大差别。</li><li>Parallel 类：包括 Parallel Scavenge 和 Parallel Old，多线程并行垃圾收集器经典组合，这个组合更注重于提高程序的吞吐量。</li><li>并发收集器：CMS 和 G1都可以并发进行垃圾收集，其中 CMS 只适用于老年代，而 G1 则横跨新生代和老年代。</li></ol><blockquote><p>并发 (concurrent)与并行 (parallel)：这里所说的并发与并行的概念和操作系统里的概念有所不同，这里的并发是指垃圾收集线程和用户线程可以同时执行，而并行是指多个垃圾收集线程同时执行，但用户线程必须暂停。</p></blockquote><h4 id="Serial"><a href="#Serial" class="headerlink" title="Serial"></a>Serial</h4><blockquote><p>HotSpot虚拟机运行在客户端模式下的默认收集器。</p><p>优点：简单而高效，没有线程交互的开销，可以获得很高的单线程收集效率。</p><p>缺点：对于交互性较强的应用而言，这种垃圾收集器是不能够接受的，比如 JavaWeb 应用</p></blockquote><h5 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h5><p>Serial（串行）收集器是最基本、历史最悠久的单线程垃圾收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。内存回收算法使用的是标记-复制算法</p><h5 id="Serial-Old-收集器"><a href="#Serial-Old-收集器" class="headerlink" title="Serial Old 收集器"></a>Serial Old 收集器</h5><p>Serial 收集器的老年代版本，内存回收算法使用的是标记-整理算法</p><p>Serial old 在 Server 模式下主要有两个用途：</p><ul><li>在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用</li><li>作为老年代 CMS 收集器的后备垃圾回收方案，在并发收集发生 Concurrent Mode Failure 时使用</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212210.png" alt="image-20220727125912217"></p><h4 id="ParNew"><a href="#ParNew" class="headerlink" title="ParNew"></a>ParNew</h4><blockquote><p>ParNew 是很多 JVM 运行在 Server 模式下新生代的默认垃圾收集器，其中一个原因是除 Serial 外，只有ParNew GC 能与 CMS 收集器配合工作。</p><ul><li>对于新生代，回收次数频繁，使用并行方式高效</li><li>对于老年代，回收次数少，使用串行方式节省资源（CPU 并行需要切换线程，串行可以省去切换线程的资源）</li></ul></blockquote><p>ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略，stop the world等等）和 Serial 收集器完全一样。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212215.png" alt="image-20220727130407378"></p><blockquote><h4 id="自JDK9开始，ParNew加CMS收集器的组合就不再是官方推荐的服务端模式下的收集器解决方案。官方希望它能完全被G1所取代，甚至还取消了ParNew加Serial-Old以及Serial加CMS这两组收集器组合的支持（其实原本也很少人这样使用），ParNew和CMS从此只能互相搭配使用。"><a href="#自JDK9开始，ParNew加CMS收集器的组合就不再是官方推荐的服务端模式下的收集器解决方案。官方希望它能完全被G1所取代，甚至还取消了ParNew加Serial-Old以及Serial加CMS这两组收集器组合的支持（其实原本也很少人这样使用），ParNew和CMS从此只能互相搭配使用。" class="headerlink" title="自JDK9开始，ParNew加CMS收集器的组合就不再是官方推荐的服务端模式下的收集器解决方案。官方希望它能完全被G1所取代，甚至还取消了ParNew加Serial Old以及Serial加CMS这两组收集器组合的支持（其实原本也很少人这样使用），ParNew和CMS从此只能互相搭配使用。"></a>自JDK9开始，ParNew加CMS收集器的组合就不再是官方推荐的服务端模式下的收集器解决方案。官方希望它能完全被G1所取代，甚至还取消了ParNew加Serial Old以及Serial加CMS这两组收集器组合的支持（其实原本也很少人这样使用），ParNew和CMS从此只能互相搭配使用。</h4></blockquote><h4 id="Parallel"><a href="#Parallel" class="headerlink" title="Parallel"></a>Parallel</h4><blockquote><p>在注重吞吐量及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge + Parallel Old 收集器，在 Server 模式下的内存回收性能很好。</p><p>JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old。</p></blockquote><h5 id="Parallel-Scavenge-收集器"><a href="#Parallel-Scavenge-收集器" class="headerlink" title="Parallel Scavenge 收集器"></a>Parallel Scavenge 收集器</h5><p>Parallel Scavenge 收集器是应用于新生代的并行垃圾回收器，采用标记—复制算法、并行回收和 Stop the World 机制</p><p>同CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）不同，Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU），所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 </p><h5 id="Parallel-Old-收集器"><a href="#Parallel-Old-收集器" class="headerlink" title="Parallel Old 收集器"></a>Parallel Old 收集器</h5><p>Parallel Scavenge 收集器的老年代版本，支持多线程并行收集，基于“标记-整理”算法实现。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212217.png" alt="image-20220727133040959"></p><blockquote><h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><p><code>-XX:+UseAdaptivesizepplicy</code>参数：设置 Parallel Scavenge 收集器具有<strong>自适应调节策略</strong>，在这种模式下，年轻代的大小、Eden 和 Survivor 的比例、晋升老年代的对象年龄等参数会被自动调整，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。用户只需要把基本的内存数据设置好（如-Xmx设置最大堆），然后使用<code>-XX：MaxGCPauseMillis</code>参数（更关注最大停顿时间）或<code>-XX：GCTimeRatio</code>（更关注吞吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。</p><p>停顿时间和吞吐量的关系：新生代空间变小 → 缩短停顿时间 → 垃圾回收变得频繁 → 导致吞吐量下降</p></blockquote><h4 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h4><p>CMS 全称 Concurrent Mark Sweep，是一款并发的、使用标记-清除算法、针对老年代的垃圾回收器，其最大特点是让垃圾收集线程与用户线程同时工作</p><p>CMS收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。</p><p>整个收集过程分为四个步骤：</p><ul><li>初始标记（stop the world）： 暂停所有的其他线程，仅标记GC Roots能直接关联到的对象，速度很快 ；</li><li>并发标记： 从GC Roots的直接关联对象开始遍历整个对象图，耗时较长，但不需要停顿用户线程，可以与垃圾收集线程一起并发运行。</li><li>重新标记（stop the world）： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短</li><li>并发清除： 开启用户线程，同时 GC 线程开始清理删除标记阶段判断的已经死亡的对象。</li></ul><blockquote><p>Mark Sweep 会造成内存碎片，不把算法换成 Mark Compact 的原因：Mark Compact 算法会整理内存，导致用户线程使用的对象的地址改变，影响用户线程继续执行</p></blockquote><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212220.png" alt="image-20220727150045496"></p><p>优点：并发收集、低停顿</p><p>缺点：</p><ul><li><p>对 CPU 资源敏感，吞吐量降低：在并发阶段虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，CPU 利用率不够高</p></li><li><p>CMS 收集器无法处理浮动垃圾，可能出现 并发失败（Concurrent Mode Failure） 导致另一次完全“Stop The World” 的Full GC 的产生</p><p>浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾（产生了新对象），这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，CMS 收集需要预留出一部分内存，不能等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 “Concurrent Mode Failure”，这时虚拟机将冻结用户线程执行，临时启用 Serial Old 来替代 CMS来重新进行老年代垃圾收集，导致很长的停顿时间</p></li><li><p>标记 - 清除算法会导致收集结束时会有大量空间碎片产生，往往出现老年代空间无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC；</p></li></ul><h4 id="G1-收集器"><a href="#G1-收集器" class="headerlink" title="G1 收集器"></a>G1 收集器</h4><blockquote><p> JDK 9发布之日，G1宣告取代Parallel Scavenge加Parallel Old组合，成为服务端模式下的默认垃圾收集器，而CMS则沦落至被声明为不推荐使用（Deprecate）的收集器</p></blockquote><p>G1（Garbage-First）是一款面向服务端应用的垃圾收集器，应用于新生代和老年代、采用标记-整理算法、软实时、低延迟,用于代替 CMS，适用于较大的堆（&gt;6 ~ 8G）。</p><p>G1具备以下特点：</p><ul><li><p>并行与并发：</p><ul><li>并行性：G1 在回收期间，可以有多个 GC 线程同时工作，有效利用多核计算能力，此时用户线程 STW</li><li>并发性：G1 拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此不会在整个回收阶段发生完全阻塞应用程序的情况</li></ul></li><li><p>分区算法：</p><ul><li><p>G1仍是遵循分代收集理论设计的，但其堆内存的布局与其他收集器有非常明显的差异：G1不再坚持固定大小以及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域（Region），新生代和老年代只是一系列区域（不需要连续）的动态集合</p></li><li><p>G1开创的基于Region的堆内存布局将整个堆划分成约 2048 个大小相同的独立 Region 块，每个 Region 块大小根据堆空间的实际大小而定，整体被控制在 1MB 到 32 MB之间且为 2 的 N 次幂。每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理，</p></li><li><p>特殊的Humongous区域：专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象，而对于那些超过了整个Region容量的超级大对象，将会被存放在N个连续的Humongous Region之中。G1的大多数行为都把Humongous Region作为老年代的一部分来进行看待</p></li><li><p>Region 结构图：</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212228.png" alt="image-20220727165020113"></p></li></ul></li><li><p>空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部（Region 之间）上来看是基于“标记-复制”算法实现的。</p></li><li><p>停顿预测模型：可以指定在 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒</p><p>G1收集器的Mixed GC模式：将Region作为单次回收的最小单元，即每次收集到的内存空间都是Region大小的整数倍（多个Region构成回收集）</p><p>G1收集器跟踪各个Region里面的垃圾堆积的“价值”大小，价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间，优先处理回收价值收益最大的那些Region。</p></li></ul><p>G1收集器的运作过程大致可划分为以下四个步骤：</p><blockquote><p>G1为每一个Region设计了两个名为TAMS（Top at Mark Start）的指针，把Region中的一部分空间划分出来用于并发回收过程中的新对象分配，并发回收时新分配的对象地址都必须要在这两个指针位置以上。G1收集器默认在这个地址以上的对象是被隐式标记过的，即默认它们是存活的，不纳入回收范围。与CMS中的“Concurrent Mode Failure”失败会导致Full GC类似，如果内存回收的速度赶不上内存分配的速度，G1收集器也要被迫冻结用户线程执行，导致Full GC而产生长时间“Stop The World”。</p></blockquote><ul><li>初始标记（Initial Marking）：仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region中分配新对象。这个阶段需要停顿线程，但耗时很短，而且是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际并没有额外的停顿。</li><li>并发标记（Concurrent Marking）：从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以后，还要重新处理SATB记录下的在并发时有引用变动的对象。</li><li>最终标记（Final Marking）：对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录。</li><li>筛选回收（Live Data Counting and Evacuation）：负责更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个Region构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间。这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行完成的。</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212231.png" alt="image-20220727172207474"></p><h4 id="低延迟垃圾收集器"><a href="#低延迟垃圾收集器" class="headerlink" title="低延迟垃圾收集器"></a>低延迟垃圾收集器</h4><h5 id="ZGC-收集器"><a href="#ZGC-收集器" class="headerlink" title="ZGC 收集器"></a>ZGC 收集器</h5><p>详情可以看 ： <a href="https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html">《新一代垃圾回收器 ZGC 的探索与实践》</a> 和   <a href="https://lanlan2017.github.io/JavaReadingNotes/daff7a57/">《ZGC收集器》</a></p><h5 id="Shenandoah收集器"><a href="#Shenandoah收集器" class="headerlink" title="Shenandoah收集器"></a>Shenandoah收集器</h5><p>详情可以看 ：<a href="https://cloud.tencent.com/developer/article/1648630">《深入理解JVM（③）低延迟的Shenandoah收集器》</a>  和  <a href="https://lanlan2017.github.io/JavaReadingNotes/9da7cb3e/">《Shenandoah收集器》</a></p><h3 id="内存分配与回收策略"><a href="#内存分配与回收策略" class="headerlink" title="内存分配与回收策略"></a>内存分配与回收策略</h3><h4 id="分配策略"><a href="#分配策略" class="headerlink" title="分配策略"></a>分配策略</h4><p>对象优先在 Eden 分配：</p><ul><li><strong>对象优先在 Eden 分配</strong>：当创建一个对象的时候，对象会被分配在新生代的 Eden 区，当 Eden 区要满了时候，触发 YoungGC</li><li>当进行 YoungGC 后，此时在 Eden 区存活的对象被移动到 to 区，并且当前对象的年龄会加 1，清空 Eden 区</li><li>当再一次触发 YoungGC 的时候，会把 Eden 区中存活下来的对象和 to 中的对象，移动到 from 区中，这些对象的年龄会加 1，清空 Eden 区和 to 区</li><li>To 区永远是空 Survivor 区，From 区是有数据的，每次 MinorGC 后两个区域互换</li><li>From 区和 To 区 也可以叫做 S0 区和 S1 区</li></ul><p>晋升到老年代：</p><ul><li><p><strong>长期存活的对象进入老年代</strong>：为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中</p><p><code>-XX:MaxTenuringThreshold</code>：定义年龄的阈值，对象头中用 4 个 bit 存储，所以最大值是 15，默认也是 15</p></li><li><p><strong>大对象直接进入老年代</strong>：需要连续内存空间的对象，最典型的大对象是很长的字符串以及数组；避免在 Eden 和 Survivor 之间的大量复制；经常出现大对象会提前触发 GC 以获取足够的连续空间分配给大对象</p><p><code>-XX:PretenureSizeThreshold</code>：大于此值的对象直接在老年代分配</p></li><li><p><strong>动态对象年龄判定</strong>：如果在 Survivor 区中相同年龄的对象的所有大小之和超过 Survivor 空间的一半，年龄大于等于该年龄的对象就可以直接进入老年代</p></li></ul><p>空间分配担保：</p><ul><li>在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的</li><li>如果不成立，虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于将尝试着进行一次 Minor GC；如果小于或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC</li></ul><h4 id="回收策略"><a href="#回收策略" class="headerlink" title="回收策略"></a>回收策略</h4><h5 id="触发条件"><a href="#触发条件" class="headerlink" title="触发条件"></a>触发条件</h5><p>内存垃圾回收机制主要集中的区域就是线程共享区域：<strong>堆和方法区</strong></p><p>Minor GC 触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC</p><p>FullGC 同时回收新生代、老年代和方法区，只会存在一个 FullGC 的线程进行执行，其他的线程全部会被<strong>挂起</strong>，有以下触发条件：</p><ul><li>调用 System.gc()：<ul><li>在默认情况下，通过 System.gc() 或 Runtime.getRuntime().gc() 的调用，会显式触发 FullGC，同时对老年代和新生代进行回收，但是虚拟机不一定真正去执行，无法保证对垃圾收集器的调用</li><li>不建议使用这种方式，应该让虚拟机管理内存。一般情况下，垃圾回收应该是自动进行的，无须手动触发；在一些特殊情况下，如正在编写一个性能基准，可以在运行之间调用 System.gc()</li></ul></li><li>老年代空间不足：<ul><li>为了避免引起的 Full GC，应当尽量不要创建过大的对象以及数组</li><li>通过 -Xmn 参数调整新生代的大小，让对象尽量在新生代被回收掉不进入老年代，可以通过 <code>-XX:MaxTenuringThreshold</code> 调大对象进入老年代的年龄，让对象在新生代多存活一段时间</li></ul></li><li>空间分配担保失败</li><li>JDK 1.7 及以前的永久代（方法区）空间不足</li><li>Concurrent Mode Failure：执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC</li></ul><h5 id="安全区域"><a href="#安全区域" class="headerlink" title="安全区域"></a>安全区域</h5><p>安全点 (Safepoint)：程序执行时并非在所有地方都能停顿下来开始 GC，只有在安全点才能停下</p><ul><li>Safe Point 的选择很重要，如果太少可能导致 GC 等待的时间太长，如果太多可能导致运行时的性能问题</li><li>大部分指令的执行时间都非常短，通常会根据是否具有让程序长时间执行的特征为标准，选择些执行时间较长的指令作为 Safe Point， 如方法调用、循环跳转和异常跳转等</li></ul><p>在 GC 发生时，让所有线程都在最近的安全点停顿下来的方法：</p><ul><li>抢先式中断：没有虚拟机采用，首先中断所有线程，如果有线程不在安全点，就恢复线程让线程运行到安全点</li><li>主动式中断：设置一个中断标志，各个线程运行到各个 Safe Point 时就轮询这个标志，如果中断标志为真，则将自己进行中断挂起</li></ul><p>问题：Safepoint 保证程序执行时，在不太长的时间内就会遇到可进入 GC 的 Safepoint，但是当线程处于 Waiting 状态或 Blocked 状态，线程无法响应 JVM 的中断请求，运行到安全点去中断挂起，JVM 也不可能等待线程被唤醒，对于这种情况，需要安全区域来解决</p><p>安全区域 (Safe Region)：指在一段代码片段中，<strong>对象的引用关系不会发生变化</strong>，在这个区域中的任何位置开始 GC 都是安全的</p><p>运行流程：</p><ul><li>当线程运行到 Safe Region 的代码时，首先标识已经进入了 Safe Region，如果这段时间内发生 GC，JVM 会忽略标识为 Safe Region 状态的线程</li><li>当线程即将离开 Safe Region 时，会检查 JVM 是否已经完成 GC，如果完成了则继续运行，否则线程必须等待 GC 完成，收到可以安全离开 SafeRegion 的信号</li></ul><h2 id="类文件结构"><a href="#类文件结构" class="headerlink" title="类文件结构"></a>类文件结构</h2><p>字节码是一种java源代码经编译之后供虚拟机解释执行的二进制字节码文件（即扩展名为 <code>.class</code> 的文件），一个 class 文件对应一个 public 类型的类或接口，它不面向任何特定的处理器，只面向虚拟机，是构成平台无关性和语言无关性的基石</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212239.png" alt="image-20220728154225714"> </p><p>根据 Java 虚拟机规范，Class 文件通过 <code>ClassFile</code> 定义，有点类似 C 语言的结构体，这种结构中只有两种数据类型：无符号数和表：</p><ul><li>无符号数属于基本的数据类型，以 u1、u2、u4、u8 来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照 UTF-8 编码构成字符串</li><li>表是由多个无符号数或者其他表作为数据项构成的复合数据类型，表都以 <code>_info</code> 结尾，用于描述有层次关系的数据，整个 Class 文件本质上就是一张表，由于表没有固定长度，所以通常会在其前面加上个数说明</li></ul><p><code>ClassFile</code> 的结构如下：</p><pre class=" language-java"><code class="language-java">ClassFile <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    u4             magic<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//Class 文件的标志</span>    u2             minor_version<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的次版本号</span>    u2             major_version<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的主版本号</span>    u2             constant_pool_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//常量池的数量</span>    cp_info        constant_pool<span class="token punctuation">[</span>constant_pool_count<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//常量池</span>    u2             access_flags<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的访问标记</span>    u2             this_class<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//当前类</span>    u2             super_class<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//父类</span>    u2             interfaces_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//接口</span>    u2             interfaces<span class="token punctuation">[</span>interfaces_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以实现多个接口</span>    u2             fields_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 文件的字段属性</span>    field_info     fields<span class="token punctuation">[</span>fields_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以有多个字段</span>    u2             methods_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 文件的方法数量</span>    method_info    methods<span class="token punctuation">[</span>methods_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以有个多个方法</span>    u2             attributes_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//此类的属性表中的属性数</span>    attribute_info attributes<span class="token punctuation">[</span>attributes_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//属性表集合</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><h4 id="魔数（Magic-Number）"><a href="#魔数（Magic-Number）" class="headerlink" title="魔数（Magic Number）"></a>魔数（Magic Number）</h4><pre class=" language-java"><code class="language-java">u4             magic<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//Class 文件的标志</span></code></pre><p>每个 Class 文件的头 4 个字节称为魔数（Magic Number）,是 Class 文件的标识符，它的唯一作用是确定这个文件是否为一个能被虚拟机接收的 Class 文件。</p><h4 id="版本号（Minor-amp-Major-Version）"><a href="#版本号（Minor-amp-Major-Version）" class="headerlink" title="版本号（Minor&amp;Major Version）"></a>版本号（Minor&amp;Major Version）</h4><pre class=" language-java"><code class="language-java">u2             minor_version<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的次版本号</span>u2             major_version<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的主版本号</span></code></pre><p>紧接着魔数的四个字节存储的是 Class 文件的版本号：第 5 和第 6 位是次版本号，第 7 和第 8 位是主版本号。</p><p>高版本的 Java 虚拟机可以执行低版本编译器生成的 Class 文件，但是低版本的 Java 虚拟机不能执行高版本编译器生成的 Class 文件。</p><h4 id="常量池（Constant-Pool）"><a href="#常量池（Constant-Pool）" class="headerlink" title="常量池（Constant Pool）"></a>常量池（Constant Pool）</h4><pre class=" language-java"><code class="language-java">u2             constant_pool_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//常量池的数量</span>cp_info        constant_pool<span class="token punctuation">[</span>constant_pool_count<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//常量池</span></code></pre><p>紧接着主次版本号之后的是常量池，常量池的数量是 <code>constant_pool_count-1</code>（常量池计数器是从 1 开始计数的，将第 0 项常量空出来是有特殊考虑的，索引值为 0 代表“不引用任何一个常量池项”）。</p><p>常量池主要存放两大常量：字面量和符号引用。字面量比较接近于 Java 语言层面的的常量概念，如文本字符串、声明为 final 的常量值等。而符号引用则属于编译原理方面的概念。包括下面三类常量：</p><ul><li>类和接口的全限定名</li><li>字段的名称和描述符</li><li>方法的名称和描述符</li></ul><p><code>.class</code> 文件可以通过<code>javap -v class类名</code> 指令来看一下其常量池中的信息</p><h4 id="访问标志-Access-Flags"><a href="#访问标志-Access-Flags" class="headerlink" title="访问标志(Access Flags)"></a>访问标志(Access Flags)</h4><pre class=" language-java"><code class="language-java"> u2             access_flags<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的访问标记</span></code></pre><p>在常量池结束之后，紧接着的两个字节代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，包括：这个 Class 是类还是接口，是否为 <code>public</code> 或者 <code>abstract</code> 类型，如果是类的话是否声明为 <code>final</code> 等等</p><h4 id="索引集合"><a href="#索引集合" class="headerlink" title="索引集合"></a>索引集合</h4><h5 id="当前类（This-Class）"><a href="#当前类（This-Class）" class="headerlink" title="当前类（This Class）"></a>当前类（This Class）</h5><pre class=" language-java"><code class="language-java">u2             this_class<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//当前类</span></code></pre><p>类索引用于确定这个类的全限定名</p><h5 id="父类（Super-Class）"><a href="#父类（Super-Class）" class="headerlink" title="父类（Super Class）"></a>父类（Super Class）</h5><pre class=" language-java"><code class="language-java">   u2             super_class<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//父类</span></code></pre><p>父类索引用于确定这个类的父类的全限定名，由于 Java 语言的单继承，所以父类索引只有一个，除了 <code>java.lang.Object</code> 之外，所有的 java 类都有父类，因此除了 <code>java.lang.Object</code> 外，所有 Java 类的父类索引都不为 0。</p><h5 id="接口（Interfaces）"><a href="#接口（Interfaces）" class="headerlink" title="接口（Interfaces）"></a>接口（Interfaces）</h5><pre class=" language-java"><code class="language-java">u2             interfaces_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//接口</span>u2             interfaces<span class="token punctuation">[</span>interfaces_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以实现多个接口</span></code></pre><p>接口索引集合用来描述这个类实现了那些接口，这些被实现的接口将按 implements (如果这个类本身是接口的话则是extends) 后的接口顺序从左到右排列在接口索引集合中</p><h4 id="字段表集合（Fields）"><a href="#字段表集合（Fields）" class="headerlink" title="字段表集合（Fields）"></a>字段表集合（Fields）</h4><pre class=" language-java"><code class="language-java">u2             fields_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 文件的字段的个数</span>field_info     fields<span class="token punctuation">[</span>fields_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类会可以有个字段</span></code></pre><p>字段表（field info）用于描述接口或类中声明的变量。字段包括类级变量以及实例变量，但不包括在方法内部声明的局部变量。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212243.png" alt="image-20220731152928551"> </p><ul><li><strong>access_flags:</strong> 字段的作用域（<code>public</code> ,<code>private</code>,<code>protected</code>修饰符），是实例变量还是类变量（<code>static</code>修饰符）,可否被序列化（transient 修饰符）,可变性（final）,可见性（volatile 修饰符，是否强制从主内存读写）。</li><li><strong>name_index:</strong> 对常量池的引用，表示的字段的名称；</li><li><strong>descriptor_index:</strong> 对常量池的引用，表示字段和方法的描述符；</li><li><strong>attributes_count:</strong> 一个字段还会拥有一些额外的属性，attributes_count 存放属性的个数；</li><li><strong>attributes[attributes_count]:</strong> 存放具体属性具体内容。</li></ul><p>上述这些信息中，各个修饰符都是布尔值，要么有某个修饰符，要么没有，很适合使用标志位来表示。而字段叫什么名字、字段被定义为什么数据类型这些都是无法固定的，只能引用常量池中常量来描述。</p><h4 id="方法表集合（Methods）"><a href="#方法表集合（Methods）" class="headerlink" title="方法表集合（Methods）"></a>方法表集合（Methods）</h4><pre class=" language-java"><code class="language-java">u2             methods_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 文件的方法的数量</span>method_info    methods<span class="token punctuation">[</span>methods_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以有个多个方法</span></code></pre><p>methods_count 表示方法的数量，而 method_info 表示方法表。</p><p>Class 文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方式。方法表的结构如同字段表一样，依次包括了访问标志、名称索引、描述符索引、属性表集合几项。</p><p>method_info(方法表的) 结构:</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212246.png" alt="image-20220731153200625"> </p><h4 id="属性表集合（Attributes）"><a href="#属性表集合（Attributes）" class="headerlink" title="属性表集合（Attributes）"></a>属性表集合（Attributes）</h4><pre class=" language-java"><code class="language-java">u2             attributes_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//此类的属性表中的属性数</span>attribute_info attributes<span class="token punctuation">[</span>attributes_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//属性表集合</span></code></pre><p>在 Class 文件，字段表，方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。与 Class 文件中其它的数据项目要求的顺序、长度和内容不同，属性表集合的限制稍微宽松一些，不再要求各个属性表具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以向属性表中写 入自己定义的属性信息，Java 虚拟机运行时会忽略掉它不认识的属性。</p><h2 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h2><p>Java虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换、解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这个过程被称作虚拟机的类加载机制。</p><h4 id="类的生命周期"><a href="#类的生命周期" class="headerlink" title="类的生命周期"></a>类的生命周期</h4><p>一个类的完整生命周期如下：</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212250.png" alt="image-20220802150118953"> </p><h4 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h4><h5 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h5><p>加载阶段和连接阶段的部分内容是交叉进行的，加载阶段尚未结束，连接阶段可能就已经开始了。</p><p><strong>数组类型没有外部二进制文件，不通过类加载器创建，它由 Java 虚拟机直接创建。</strong></p><ol><li>通过全类名（包名+类名）获取定义此类的二进制字节流</li><li>将字节流所代表的静态存储结构转换为方法区的运行时数据结构</li><li>在内存中生成一个代表该类的 <code>java.lang.Class</code> 对象，作为方法区这些数据的访问入口</li></ol><h5 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h5><p>验证阶段目的是为了确保Class文件的字节流包含的信息符合当前虚拟机的要求，确保Java虚拟机不受恶意代码的攻击</p><ol><li><p>文件格式验证</p><p>验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理</p></li><li><p>元数据验证</p><p>对字节码描述的信息进行语义分析，以保证其描述的信息符合《Java语言规范》的要求</p></li><li><p>字节码验证</p><p>通过·数据流和控制流分析，确定程序语义合法，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件</p></li><li><p>符号引用验证</p><p>发生在虚拟机将符号引用转化为直接引用的时候，即“解析”阶段，，对类自身以外的各类信息进行匹型校验，确保解析行为能正常执行</p></li></ol><h5 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h5><p>准备阶段是正式为类变量（即类中定义的静态变量）分配内存并设置类变量初始值的阶段</p><ul><li>这时候进行内存分配的仅包括类变量，而不包括实例变量。实例变量会在对象实例化时随着对象一块分配在 Java 堆中。</li><li>从概念上讲，类变量所使用的内存都应当在 方法区 中进行分配。不过有一点需要注意的是：JDK 7 之前，HotSpot 使用永久代来实现方法区的时候，实现是完全符合这种逻辑概念的。 而在 JDK 7 及之后，HotSpot 已经把原本放在永久代的字符串常量池、静态变量等移动到堆中，这个时候类变量则会随着 Class 对象一起存放在 Java 堆中。</li><li>这里所设置的初始值”通常情况”下是数据类型默认的零值。特殊情况：比如给 value 变量加上了 final 关键字<code>public static final int value=111</code> ，那么准备阶段 value 的值就被赋值为 111。</li></ul><h5 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h5><p>解析阶段是虚拟机将常量池的符号引用直接替换为直接引用的过程。</p><p>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符 7 类符号引用进行。</p><ul><li>符号引用就是一组符号来描述目标，可以是任何字面量。</li><li>直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。</li></ul><h5 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h5><p>初始化阶段是执行类构造器 <code>&lt;clinit&gt; ()</code>方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。</p><blockquote><p>说明： <code>&lt;clinit&gt; ()</code>方法是Javac编译器的自动生产物</p></blockquote><ul><li>&lt; clinit&gt;()方法方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的。</li><li>虚拟机会保证一个类的&lt; clinit&gt;()方法在多线程环境中被正确地加锁和同步</li></ul><p>对于初始化阶段，虚拟机严格规范了有且只有6种情况下，必须对类进行初始化(只有主动去使用类才会初始化类)：</p><ol><li><p>当遇到 <code>new</code> 、 <code>getstatic</code>、<code>putstatic</code> 或 <code>invokestatic</code> 这 4 条字节码指令时，比如 <code>new</code> 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。</p><ul><li>当 jvm 执行 <code>new</code> 指令时会初始化类。即当程序创建一个类的实例对象。</li><li>当 jvm 执行 <code>getstatic</code> 指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。</li><li>当 jvm 执行 <code>putstatic</code> 指令时会初始化类。即程序给类的静态变量赋值。</li><li>当 jvm 执行 <code>invokestatic</code> 指令时会初始化类。即程序调用类的静态方法。</li></ul></li><li><p>使用 <code>java.lang.reflect</code> 包的方法对类进行反射调用时如 <code>Class.forname(&quot;...&quot;)</code>, <code>newInstance()</code> 等等。如果类没初始化，需要触发其初始化。</p></li><li><p>初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。</p></li><li><p>当虚拟机启动时，用户需要定义一个要执行的主类 (包含 <code>main</code> 方法的那个类)，虚拟机会先初始化这个类。</p></li><li><p><code>MethodHandle</code> 和 <code>VarHandle</code> 可以看作是轻量级的反射调用机制，而要想使用这 2 个调用， 就必须先使用 <code>findStaticVarHandle</code> 来初始化要调用的类。</p></li><li><p>当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。</p></li></ol><h4 id="类卸载"><a href="#类卸载" class="headerlink" title="类卸载"></a>类卸载</h4><p>卸载类即该类的 Class 对象被 GC。</p><p>卸载类需要满足 3 个要求:</p><ol><li>该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。</li><li>该类没有在其他任何地方被引用</li><li>该类的类加载器的实例已被 GC</li></ol><p>所以，在 JVM 生命周期内，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。</p><h4 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h4><h5 id="类加载器总结"><a href="#类加载器总结" class="headerlink" title="类加载器总结"></a>类加载器总结</h5><blockquote><p>实现类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作的代码被称为类加载器</p></blockquote><p>JVM 中内置了三个重要的 ClassLoader，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自抽象类<code>java.lang.ClassLoader</code>：</p><ul><li><p>BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由 C++实现，是虚拟机自身的一部分，负责加载 <code>%JAVA_HOME%/lib</code>目录下的 jar 包和类或者被 <code>-Xbootclasspath</code>参数指定的路径中的所有类。</p></li><li><p>ExtensionClassLoader(扩展类加载器) ：主要负责加载 <code>%JRE_HOME%/lib/ext</code> 目录下的 jar 包和类，或被 <code>java.ext.dirs</code> 系统变量所指定的路径下的 jar 包。</p></li><li><p>AppClassLoader(应用程序类加载器) ：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。</p></li></ul><h5 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h5><p>除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器，但类加载器之间的父子关系一般不以继承的关系实现，而是通常使用组合关系来复用父类加载的代码。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317212254.png" alt="image-20220909150850743" style="zoom:67% ;" /> <p>系统中的 ClassLoader 在协同工作的时候会默认使用 双亲委派模型 :即在类加载的时候，类加载器会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派给父类加载器的 <code>loadClass()</code> 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 <code>BootstrapClassLoader</code> 中。只有当父类加载器反馈自己无法处理（他的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。当父类加载器为 null 时，则默认使用启动类加载器 <code>BootstrapClassLoader</code> 作为父类加载器。</p><p>双亲委派模型的实现代码非常简单，逻辑非常清晰，都集中在 <code>java.lang.ClassLoader</code> 的 <code>loadClass()</code> 中，相关代码如下所示。</p><pre class=" language-java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">final</span> ClassLoader parent<span class="token punctuation">;</span><span class="token keyword">protected</span> Class<span class="token operator">&lt;</span><span class="token operator">?</span><span class="token operator">></span> <span class="token function">loadClass</span><span class="token punctuation">(</span>String name<span class="token punctuation">,</span> <span class="token keyword">boolean</span> resolve<span class="token punctuation">)</span>        <span class="token keyword">throws</span> ClassNotFoundException    <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">synchronized</span> <span class="token punctuation">(</span><span class="token function">getClassLoadingLock</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 首先，检查请求的类是否已经被加载过</span>            Class<span class="token operator">&lt;</span><span class="token operator">?</span><span class="token operator">></span> c <span class="token operator">=</span> <span class="token function">findLoadedClass</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>c <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token keyword">long</span> t0 <span class="token operator">=</span> System<span class="token punctuation">.</span><span class="token function">nanoTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>parent <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//父加载器不为空，调用父加载器loadClass()方法处理</span>                        c <span class="token operator">=</span> parent<span class="token punctuation">.</span><span class="token function">loadClass</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//父加载器为空，使用启动类加载器 BootstrapClassLoader 加载</span>                        c <span class="token operator">=</span> <span class="token function">findBootstrapClassOrNull</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClassNotFoundException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                   <span class="token comment" spellcheck="true">//抛出异常说明父类加载器无法完成加载请求</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>c <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token keyword">long</span> t1 <span class="token operator">=</span> System<span class="token punctuation">.</span><span class="token function">nanoTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token comment" spellcheck="true">//自己尝试加载</span>                    c <span class="token operator">=</span> <span class="token function">findClass</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token comment" spellcheck="true">// this is the defining class loader; record the stats</span>                    sun<span class="token punctuation">.</span>misc<span class="token punctuation">.</span>PerfCounter<span class="token punctuation">.</span><span class="token function">getParentDelegationTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">addTime</span><span class="token punctuation">(</span>t1 <span class="token operator">-</span> t0<span class="token punctuation">)</span><span class="token punctuation">;</span>                    sun<span class="token punctuation">.</span>misc<span class="token punctuation">.</span>PerfCounter<span class="token punctuation">.</span><span class="token function">getFindClassTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">addElapsedTimeFrom</span><span class="token punctuation">(</span>t1<span class="token punctuation">)</span><span class="token punctuation">;</span>                    sun<span class="token punctuation">.</span>misc<span class="token punctuation">.</span>PerfCounter<span class="token punctuation">.</span><span class="token function">getFindClasses</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">increment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>resolve<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token function">resolveClass</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> c<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><h5 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a>自定义类加载器</h5><p>自定义加载器的话，需要继承 <code>ClassLoader</code> 。如果我们不想打破双亲委派模型，就重写 <code>ClassLoader</code> 类中的 <code>findClass()</code> 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 <code>loadClass()</code> 方法。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL</title>
      <link href="/2023/03/17/mysql/"/>
      <url>/2023/03/17/mysql/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL-基础架构"><a href="#MySQL-基础架构" class="headerlink" title="MySQL 基础架构"></a>MySQL 基础架构</h2><p>下面就是 MySQL 执行一条 SQL 查询语句的流程，也从图中可以看到 MySQL 内部架构里的各个功能模块。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210445.png" alt="image-20220910143828625" style="zoom: 67%;" />  <p>MySQL 的架构共分为两层：Server 层和存储引擎层:</p><ul><li><p>server 层负责建立连接、分析和执行 SQL。所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。</p><p>包含大多数的核心功能模：</p><ul><li><p>连接器： 身份认证和权限相关</p><p>登录 MySQL 的时候，与客户端进行 TCP 三次握手建立连接；校验客户端的用户名和密码；若用户密码正确，连接器会读取该用户的权限并保存，然后后面的权限逻辑判断都基于此时读取到的权限。</p></li></ul><ul><li><p>查询缓存： 执行查询语句的时候，会先去查询缓存（ Query Cache ）里查找缓存数据</p><p>查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。</p><p>MySQL 8.0 版本后移除，因为这个功能不太实用：表更新时会清空查询缓存。</p></li><li><p>分析器： 没有命中缓存的话，SQL 语句就会经过分析器，对sql语句做解析。</p><p>词法分析：MySQL 会根据你输入的字符串识别出关键字出来，构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。</p><p>语法分析：根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。</p></li><li><p>优化器：基于查询成本，选择索引， 按照 MySQL 认为最优的方案去执行。</p></li><li><p>执行器： 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。</p></li></ul></li></ul><h2 id="MySQL-存储引擎"><a href="#MySQL-存储引擎" class="headerlink" title="MySQL 存储引擎"></a>MySQL 存储引擎</h2><p>MySQL 支持多种存储引擎，你可以通过 <code>show engines</code> 命令来查看 MySQL 支持的所有存储引擎。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210452.png" alt="image-20220910160112498"></p><p>MySQL 5.5.5 之前，MyISAM 是 MySQL 的默认存储引擎。5.5.5 版本之后，InnoDB 是 MySQL 的默认存储引擎。</p><p>MySQL 存储引擎采用的是插件式架构，支持多种存储引擎，我们甚至可以为不同的数据库表设置不同的存储引擎以适应不同场景的需要。存储引擎是基于表的，而不是数据库。</p><p><strong>MyISAM 和 InnoDB 的区别</strong></p><ul><li><p>MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁</p></li><li><p>MyISAM 不提供事务支持，InnoDB 提供事务支持</p></li><li><p>MyISAM 不支持外键，而 InnoDB 支持外键</p></li><li><p>MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持，依赖于 <code>redo log</code> </p></li></ul><h2 id="MySQL索引"><a href="#MySQL索引" class="headerlink" title="MySQL索引"></a>MySQL索引</h2><p>索引是一种用于快速查询和检索数据的数据结构，形象的说就是索引是数据的目录。</p><h3 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h3><h4 id="按数据结构分类"><a href="#按数据结构分类" class="headerlink" title="按数据结构分类"></a>按数据结构分类</h4><p>从数据结构的角度来看，MySQL 常见索引有： B 树， B+树和 Hash。</p><p>B+树索引类型是 MySQL 存储引擎采用最多的索引类型。</p><h5 id="B-树-vs-B树"><a href="#B-树-vs-B树" class="headerlink" title="B+树 vs B树"></a>B+树 vs B树</h5><p>B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。</p><h5 id="B-树-vs-Hash"><a href="#B-树-vs-Hash" class="headerlink" title="B+树 vs Hash"></a>B+树 vs Hash</h5><p>Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。但是 Hash 表不支持顺序和范围查询。</p><h4 id="按物理存储分类"><a href="#按物理存储分类" class="headerlink" title="按物理存储分类"></a>按物理存储分类</h4><p>从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。</p><h5 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h5><p>聚簇索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；</p><p>在创建表时，InnoDB 存储引擎会根据不同的场景选择不同的列作为索引：</p><ul><li>如果有主键，默认会使用主键作为聚簇索引的索引键（key）；</li><li>如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）；</li><li>在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210459.png" alt="主键索引 B+Tree"></p><h5 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h5><p>二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210503.png" alt="二级索引 B+Tree"></p><h6 id="回表"><a href="#回表" class="headerlink" title="回表"></a>回表</h6><p>如果用二级索引查询，会先检索二级索引中的 B+Tree 的索引值（商品编码，product_no），找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据</p><h6 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h6><p>当查询的数据是能在二级索引的 B+Tree 的叶子节点里查询到（如二级索引自身），这时就不用再查主键索引查。这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据。</p><h4 id="按字段特性分类"><a href="#按字段特性分类" class="headerlink" title="按字段特性分类"></a>按字段特性分类</h4><p>从字段特性的角度来看，索引分为主键索引、唯一索引、普通索引、前缀索引</p><p>唯一索引、普通索引、前缀索引都属于二级索引</p><h5 id="主键索引"><a href="#主键索引" class="headerlink" title="主键索引"></a>主键索引</h5><p>主键索引就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。</p><h5 id="唯一索引"><a href="#唯一索引" class="headerlink" title="唯一索引"></a>唯一索引</h5><p>唯一索引建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。</p><p> 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。</p><h5 id="普通索引"><a href="#普通索引" class="headerlink" title="普通索引"></a>普通索引</h5><p>普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。</p><p>普通索引的唯一作用就是为了快速查询数据</p><h5 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h5><p>前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。</p><p>使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率。</p><h4 id="按字段个数分类"><a href="#按字段个数分类" class="headerlink" title="按字段个数分类"></a>按字段个数分类</h4><p>从字段个数的角度来看，索引分为单列索引、联合索引（复合索引）。</p><ul><li>建立在单列上的索引称为单列索引，比如主键索引；</li><li>建立在多列上的索引称为联合索引；</li></ul><h5 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h5><p>通过将多个字段组合成一个索引，该索引就被称为联合索引，联合索引<code>(product_no, name)</code> 的 B+Tree 示意图如下：</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210509.png" alt="联合索引"></p><p>使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配，即先按 product_no 字段比较，在 product_no 相同的情况下再按 name 字段比较。</p><p>联合索引的最左匹配原则，在遇到范围查询（&gt;、&lt;、between、like 包括like ‘林%’这种）的时候，就会停止匹配，也就是范围列可以用到联合索引，但是范围列后面的列无法用到联合索引。</p><p>对于联合索引（a, b），在执行 <code>select * from table where a &gt; 1 and b = 2</code> 语句的时候，只有 a 字段能用到索引，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后，还需要判断其他条件是否满足（看 b 是否等于 2），那是在联合索引里判断？还是回主键索引去判断呢？</p><ul><li>在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。</li><li>而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</li></ul><h3 id="索引优缺"><a href="#索引优缺" class="headerlink" title="索引优缺"></a>索引优缺</h3><p><strong>优点</strong> ：</p><ul><li>使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。</li><li>通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。</li></ul><p><strong>索引适用</strong></p><ul><li>字段有唯一性限制的，比如商品编码；</li><li>经常用于 <code>WHERE</code> 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。</li><li>经常用于 <code>GROUP BY</code> 和 <code>ORDER BY</code> 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。</li></ul><p><strong>缺点</strong> ：</p><ul><li>创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。</li><li>索引需要使用物理文件存储，也会耗费一定空间。</li></ul><p><strong>索引不适用</strong></p><ul><li><p><code>WHERE</code> 条件，<code>GROUP BY</code>，<code>ORDER BY</code> 里用不到的字段</p></li><li><p>字段中存在大量重复数据</p></li><li><p>表数据太少</p></li><li><p>经常更新的字段</p></li></ul><h3 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h3><h4 id="前缀索引优化"><a href="#前缀索引优化" class="headerlink" title="前缀索引优化"></a>前缀索引优化</h4><p>使用某个字段中字符串的前几个字符建立索引，可以减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。</p><p>局限：</p><ul><li><code>order by</code> 就无法使用前缀索引；</li><li>无法把前缀索引用作覆盖索引；</li></ul><h4 id="覆盖索引优化"><a href="#覆盖索引优化" class="headerlink" title="覆盖索引优化"></a>覆盖索引优化</h4><p>覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。</p><p>假设只需要查询商品的名称、价格，我们可以建立一个联合索引，即「商品ID、名称、价格」作为一个联合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表。</p><p>所以，使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。</p><h4 id="主键索引自增"><a href="#主键索引自增" class="headerlink" title="主键索引自增"></a>主键索引自增</h4><p>在使用 InnoDB 存储引擎时，如果没有特别的业务需求，建议使用自增字段作为主键，从而使每次插入一条新记录，都是追加操作，不需要重新移动数据。</p><h4 id="索引NOT-NUL"><a href="#索引NOT-NUL" class="headerlink" title="索引NOT NUL"></a>索引NOT NUL</h4><p>索引列要设置为 NOT NULL 约束，因为对于数据为 NULL 的字段，数据库较难优化</p><p>如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。</p><h4 id="防止索引失效"><a href="#防止索引失效" class="headerlink" title="防止索引失效"></a>防止索引失效</h4><p>避免写出索引失效的查询语句，常见的索引失效场景：</p><ul><li>当我们使用左或者左右模糊匹配的时候，也就是 <code>like %xx</code> 或者 <code>like %xx%</code>这两种方式都会造成索引失效；</li><li>当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；</li><li>联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。</li><li>在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。</li></ul><h3 id="EXPLAIN"><a href="#EXPLAIN" class="headerlink" title="EXPLAIN"></a>EXPLAIN</h3><pre class=" language-sql"><code class="language-sql">mysql<span class="token operator">></span> <span class="token keyword">explain</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> user_info <span class="token keyword">where</span> id <span class="token operator">=</span> <span class="token number">2</span>\G<span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token keyword">row</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>           id: <span class="token number">1</span>              select_type: <span class="token keyword">SIMPLE</span>        <span class="token keyword">table</span>: user_info   partitions: <span class="token boolean">NULL</span>         <span class="token keyword">type</span>: constpossible_keys: <span class="token keyword">PRIMARY</span>          <span class="token keyword">key</span>: <span class="token keyword">PRIMARY</span>      key_len: <span class="token number">8</span>          ref: const         <span class="token keyword">rows</span>: <span class="token number">1</span>     filtered: <span class="token number">100.00</span>        Extra: <span class="token boolean">NULL</span><span class="token number">1</span> <span class="token keyword">row</span> <span class="token operator">in</span> <span class="token keyword">set</span><span class="token punctuation">,</span> <span class="token number">1</span> warning <span class="token punctuation">(</span><span class="token number">0.00</span> sec<span class="token punctuation">)</span></code></pre><p>各列的含义如下:</p><ul><li>id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.</li><li>select_type: SELECT 查询的类型.</li><li>table: 查询的是哪个表</li><li>partitions: 匹配的分区</li><li>type: join 类型</li><li>possible_keys: 此次查询中可能选用的索引</li><li>key: 此次查询中确切使用到的索引.</li><li>ref: 哪个字段或常数与 key 一起被使用</li><li>rows: 显示此查询一共扫描了多少行. 这个是一个估计值.</li><li>filtered: 表示此查询条件所过滤的数据的百分比</li><li>extra: 额外的信息</li></ul><h3 id="type"><a href="#type" class="headerlink" title="type"></a>type</h3><ul><li><code>const</code>: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据</li><li><code>eq_ref</code>: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 <code>=</code>, 查询效率较高</li><li><code>ref</code>: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 <code>最左前缀</code> 规则索引的查询.</li><li><code>range</code>: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中.</li><li><code>index</code>: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.<code>index</code> 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 <code>Using index</code>.</li><li>ALL: 表示全表扫描,</li></ul><h3 id="Extra"><a href="#Extra" class="headerlink" title="Extra"></a>Extra</h3><ul><li>Using filesort<br>当 Extra 中有 <code>Using filesort</code> 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 <code>Using filesort</code>, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大.</li><li>Using index<br>“覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错</li><li>Using temporary<br>查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210518.png" alt="img"></p><h2 id="MySQL事务"><a href="#MySQL事务" class="headerlink" title="MySQL事务"></a>MySQL事务</h2><blockquote><p><a href="https://xiaolincoding.com/mysql/transaction/mvcc.html#%E4%BA%8B%E5%8A%A1%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E6%80%A7">事务隔离级别是怎么实现的</a></p></blockquote><p>事务是逻辑上的一组操作，要么都执行，要么都不执行，由MySQL的InnoDB 引擎实现。</p><pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true"># 开启一个事务</span><span class="token keyword">START</span> <span class="token keyword">TRANSACTION</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 多条 SQL 语句</span>SQL1<span class="token punctuation">,</span>SQL2<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token comment" spellcheck="true"># 提交事务</span><span class="token keyword">COMMIT</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 回滚事务</span><span class="token keyword">ROLLBACK</span><span class="token punctuation">;</span></code></pre><h3 id="事务特性"><a href="#事务特性" class="headerlink" title="事务特性"></a>事务特性</h3><p>关系型数据库（例如：<code>MySQL</code>、<code>SQL Server</code>、<code>Oracle</code> 等）事务都有 <strong>ACID</strong> 特性：</p><ol><li><strong>原子性</strong>（<code>Atomicity</code>） ： 事务是最小的执行单位，不允许分割。一个事务中的所有操作，要么全部完成，要么全部不完成；</li><li><strong>一致性</strong>（<code>Consistency</code>）： 执行事务前后，数据满足完整性约束，保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；</li><li><strong>隔离性</strong>（<code>Isolation</code>）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li><li><strong>持久性</strong>（<code>Durabilily</code>）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li></ol><p>InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p><ul><li>持久性是通过 <code>redo log</code> （重做日志）来保证的；</li><li>原子性是通过 <code>undo log</code>（回滚日志） 来保证的；</li><li>隔离性是通过 <code>MVCC</code>（多版本并发控制） 或锁机制来保证的；</li><li>一致性则是通过持久性+原子性+隔离性来保证；</li></ul><h3 id="并发事务问题"><a href="#并发事务问题" class="headerlink" title="并发事务问题"></a>并发事务问题</h3><h4 id="读-写问题"><a href="#读-写问题" class="headerlink" title="读-写问题"></a>读-写问题</h4><p>有线程安全问题，可能会造成事务隔离性问题</p><h5 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h5><p>一个事务「==读到==」了另一个「==未提交事务修改过的数据==」</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210524.png" alt="图片" style="zoom: 67%;" /> <h5 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h5><p>在一个事务内多次读取同一个数据，出现前后两次读到的数据不一样的情况</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210528.png" alt="图片" style="zoom: 67%;" /> <h5 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h5><p>在一个事务内多次查询某个符合查询条件的「记录数量」，出现前后两次查询到的记录数量不一样的情况</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210533.png" alt="图片" style="zoom:67%;" /> <h4 id="写-写问题"><a href="#写-写问题" class="headerlink" title="写-写问题"></a>写-写问题</h4><p>有线程安全问题，可能会存在更新丢失问题</p><h5 id="第一类丢失更新"><a href="#第一类丢失更新" class="headerlink" title="第一类丢失更新"></a>第一类丢失更新</h5><p>A事务撤销时, 把已经提交的B事务的更新数据覆盖了</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210539.png" alt="clipboard.png"> </p><p>InnoDB存储引擎的隔离级别都使用了排他锁，这类更新丢失问题是不会出现的</p><h5 id="第二类丢失更新"><a href="#第二类丢失更新" class="headerlink" title="第二类丢失更新"></a>第二类丢失更新</h5><p>A事务覆盖B事务已经提交的数据，造成B事务所做操作丢失 </p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210543.png" alt="clipboard.png"> </p><p>此类更新丢失问题, 无法依靠前三种隔离级别来解决, 只能用最高隔离级别 <code>Serializable</code> 或者手动使用<code>乐观锁</code>, <code>悲观锁</code>来解决。</p><h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h3><p>SQL 标准提出了四种隔离级别来规避这些读-写问题，隔离级别越高，性能效率就越低，这四个隔离级别如下：</p><ul><li>读取未提交（<code>read uncommitted</code>），指一个事务还没提交时，它做的变更就能被其他事务看到；</li><li>读取已提交（<code>read committed</code>），指一个事务提交之后，它做的变更才能被其他事务看到；</li><li>可重复读（<code>repeatable read</code>），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；</li><li>串行化（<code>serializable</code> ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；</li></ul><p>针对不同的隔离级别，并发事务时可能发生的现象也会不同</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210550.png" alt="图片" style="zoom:67%;" /> <ul><li><p><strong>解决脏读现象，就要升级到「读提交」以上的隔离级别；</strong></p></li><li><p><strong>要解决不可重复读现象，就要升级到「可重复读」的隔离级别。</strong></p></li><li><p>解决幻读现象不建议将隔离级别升级到「串行化」，因为这样会导致数据库在并发事务时性能很差。</p><p><strong>InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它通过next-key lock 锁（行锁和间隙锁的组合）来锁住记录之间的“间隙”和记录本身，防止其他事务在这个记录之间插入新的记录，这样就避免了幻读现象。</strong></p></li></ul><p>这四种隔离级别具体是如何实现的呢？</p><ul><li>对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；</li><li>对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；</li><li>对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过<strong>Read View 来实现的，它们的区别在于创建 Read View 的时机不同， Read View 可以理解成一个数据快照。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。</strong></li></ul><h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><p>MVCC，全称<code>Multi-Version Concurrency Control</code>，即多版本并发控制，是通过「版本链」来控制并发事务访问同一个记录时的行为，从而实现读（快照读）-写冲突不加锁。</p><ul><li><p>当前读</p><blockquote><p>当前读实际上是一种加锁的操作，是悲观锁的实现</p></blockquote><p>像<code>select lock in share mode</code>(共享锁), <code>select for update</code> ; <code>update</code>, <code>insert</code> ,<code>delete</code>(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁</p></li><li><p>快照读</p><p>像不加锁的<code>select</code>操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，能读到的并不一定是数据的最新版本，而有可能是之前的历史版本</p></li></ul><h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><blockquote><p><strong>MVCC 通过隐式字段、undo log 和 Read View实现</strong></p></blockquote><h6 id="隐式字段"><a href="#隐式字段" class="headerlink" title="隐式字段"></a>隐式字段</h6><p>聚簇索引记录除了我们自己定义的字段外，还有数据库隐式定义的字段</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210556.png" alt="image-20220913153654174" style="zoom:50%;" /> <ul><li><p><code>DB_TRX_ID</code>：表示最后一次插入或更新该行的事务 id。此外，<code>delete</code> 操作在内部被视为更新，只不过会在记录头 <code>Record header</code> 中的 <code>deleted_flag</code> 字段将其标记为已删除</p></li><li><p><code>DB_ROLL_PTR</code>，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后<strong>这个隐藏列是个指针，指向每一个旧版本记录</strong>，于是就可以通过它找到修改前的记录。</p></li><li><p><code>DB_ROW_ID</code>：如果没有设置主键且该表没有唯一非空索引时，<code>InnoDB</code> 会使用该 id 来生成聚簇索引</p></li></ul><h6 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h6><p><code>undo log</code> 称为回滚日志，用于保存数据更新之前版本的数据，在事务进行 rollback 时可以直接进行数据恢复。同时由于多版本历史数据的存在，我们可以去读取旧版本的数据，快照读就是通过读取旧版本的数据实现的。</p><p>在 <code>InnoDB</code> 存储引擎中 <code>undo log</code> 分为两种： <code>insert undo log</code> 和 <code>update undo log</code>：</p><ol><li><code>insert undo log</code> ：指在 <code>insert</code> 操作中产生的 <code>undo log</code>。因为 <code>insert</code> 操作的记录只对事务本身可见，对其他事务不可见，故该 <code>undo log</code> 可以在事务提交后直接删除。不需要进行 <code>purge</code> 操作</li><li><code>update undo log</code> ：<code>update</code> 或 <code>delete</code> 操作中产生的 <code>undo log</code>。该 <code>undo log</code>可能需要提供 <code>MVCC</code> 机制，因此不能在事务提交时就进行删除。提交时放入 <code>undo log</code> 链表，等待 <code>purge线程</code> 进行最后的删除</li></ol><h6 id="Read-View"><a href="#Read-View" class="headerlink" title="Read View"></a>Read View</h6><p><code>Read View</code> 主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210602.png" alt="img" style="zoom:80%;" /> <p>Read View 有四个重要的字段：</p><ul><li>m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li><li>min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li><li>max_trx_id ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li><li>creator_trx_id ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li></ul><p>在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210608.png" alt="img"> </p><h4 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h4><p>事务每次读取记录时，会查看这条记录的 trx_id 值，</p><ul><li><p>如果在事务的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，如果在，那么说明这条记录是被还未提交的事务修改的，这时事务 并不会读取这个版本的记录。而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务  的 Read View 中的 min_trx_id 值的第一条记录</p></li><li><p>如果 trx_id事务的 Read View 中的 min_trx_id 值小，这意味着修改这条记录的事务早就在事务启动前提交过了，所以该版本的记录对事务 可见的，也就是事务可以获取到这条记录。</p></li></ul><h4 id="可重复读实现机制"><a href="#可重复读实现机制" class="headerlink" title="可重复读实现机制"></a>可重复读实现机制</h4><p><strong>可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View</strong>。</p><h4 id="读取已提交实现机制"><a href="#读取已提交实现机制" class="headerlink" title="读取已提交实现机制"></a>读取已提交实现机制</h4><p><strong>读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View</strong>。</p><h2 id="MySQL锁"><a href="#MySQL锁" class="headerlink" title="MySQL锁"></a>MySQL锁</h2><blockquote><p>InnoDB 不光支持表级锁(table-level locking)，还支持行级锁(row-level locking)，默认为行级锁</p></blockquote><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><p>MySQL 中锁定粒度最大的一种锁，是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。</p><h3 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h3><p>MySQL 中锁定粒度最小的一种锁，是针对索引字段加的锁，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。</p><blockquote><p>InnoDB 的行锁是针对索引字段加的锁，表级锁是针对非索引字段加的锁。当我们执行 <code>UPDATE</code>、<code>DELETE</code> 语句时，如果 <code>WHERE</code>条件中字段没有命中唯一索引或者索引失效的话，就会导致扫描全表对表中的所有行记录进行加锁。</p></blockquote><p>MySQL InnoDB 支持三种行锁定方式：</p><ul><li><strong>记录锁（Record Lock）</strong> ：也被称为记录锁，属于单个行记录上的锁。</li><li><strong>间隙锁（Gap Lock）</strong> ：锁定一个范围，不包括记录本身。</li><li><strong>临键锁（Next-key Lock）</strong> ：Record Lock+Gap Lock，锁定一个范围，包含记录本身。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。</li></ul><h3 id="共享锁和排他锁"><a href="#共享锁和排他锁" class="headerlink" title="共享锁和排他锁"></a>共享锁和排他锁</h3><p>不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类</p><ul><li>共享锁（S 锁） ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。</li><li>排他锁（X 锁） ：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）</li></ul><p>排他锁与任何的锁都不兼容，共享锁仅和共享锁兼容。</p><table><thead><tr><th align="left"></th><th align="center">S 锁</th><th>X 锁</th></tr></thead><tbody><tr><td align="left">S 锁</td><td align="center">不冲突</td><td>冲突</td></tr><tr><td align="left">X 锁</td><td align="center">冲突</td><td>冲突</td></tr></tbody></table><p>由于 MVCC 的存在，对于一般的 <code>SELECT</code> 语句，InnoDB 不会加任何锁。可以通过以下语句显式加共享锁或排他锁。</p><pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true"># 共享锁</span><span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">LOCK</span> <span class="token operator">IN</span> <span class="token keyword">SHARE MODE</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 排他锁</span><span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">FOR</span> <span class="token keyword">UPDATE</span><span class="token punctuation">;</span></code></pre><h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p>意向锁是表级锁，用来快速判断是否可以对某个表使用表锁，共有两种：</p><ul><li>意向共享锁（Intention Shared Lock，IS 锁）：事务有意向对表中的某些记录加共享锁（S 锁），加共享锁前必须先取得该表的 IS 锁。</li><li>意向排他锁（Intention Exclusive Lock，IX 锁）：事务有意向对表中的某些记录加排他锁（X 锁），加排他锁之前必须先取得该表的 IX 锁。</li></ul><p>意向锁是由数据引擎自己维护的，用户无法手   动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。</p><p>意向锁之间是互相兼容的。</p><table><thead><tr><th></th><th>IS 锁</th><th>IX 锁</th></tr></thead><tbody><tr><td>IS 锁</td><td>兼容</td><td>兼容</td></tr><tr><td>IX 锁</td><td>兼容</td><td>兼容</td></tr></tbody></table><h2 id="MySQL日志"><a href="#MySQL日志" class="headerlink" title="MySQL日志"></a>MySQL日志</h2><p><code>MySQL</code> 日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中，比较重要的还要属二进制日志 <code>binlog</code>（归档日志）和事务日志 <code>redo log</code>（重做日志）和 <code>undo log</code>（回滚日志）</p><ul><li><strong>undo log（回滚日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>原子性</strong>，主要<strong>用于事务回滚和 MVCC</strong>。</li><li><strong>redo log（重做日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>持久性</strong>，主要<strong>用于掉电等故障恢复</strong>；</li><li><strong>binlog （归档日志）</strong>：是 Server 层生成的日志，主要<strong>用于数据备份和主从复制</strong>；</li></ul><h3 id="undo-log-1"><a href="#undo-log-1" class="headerlink" title="undo log"></a>undo log</h3><p>undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。</p><p>每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如：</p><ul><li>在<strong>插入</strong>一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录<strong>删掉</strong>就好了；</li><li>在<strong>删除</strong>一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录<strong>插入</strong>到表中就好了；</li><li>在<strong>更新</strong>一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列<strong>更新为旧值</strong>就好了。</li></ul><p>undo log 有两大作用：</p><ul><li><strong>实现事务回滚，保障事务的原子性</strong>。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。</li><li><strong>实现 MVCC（多版本并发控制）关键因素之一</strong>。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。</li></ul><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><blockquote><p>redo log 是物理日志，记录了某个数据页做了什么修改，每条 redo 记录由“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”组成</p><ul><li><strong>实现事务的持久性，让 MySQL 有 crash-safe 的能力</strong>，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；</li><li><strong>将写操作从「随机写」变成了「顺序写」</strong>，提升 MySQL 写入磁盘的性能</li></ul></blockquote><p>Innodb 存储引擎设计了一个<strong>缓冲池（Buffer Pool）</strong>，来提高数据库的读写性能。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210616.png" alt="img" style="zoom:50%;" /> <ul><li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li><li>当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。</li></ul><p>Buffer Pool 是基于内存的，如果断电重启，还没来得及落盘的脏页数据就会丢失。</p><p>因此，InnoDB 引擎使用了WAL （Write-Ahead Logging）技术： <strong>MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上</strong>。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210620.png" alt="img" style="zoom: 50%;" /> <p>在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。</p><p>当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。</p><p>所以有了 redo log，再通过 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失，这个能力称为 <strong>crash-safe</strong>（崩溃恢复）</p><blockquote><p>redo log 和 undo log 区别</p></blockquote><p>这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：</p><ul><li>redo log 记录了此次事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值；</li><li>undo log 记录了此次事务「<strong>开始前</strong>」的数据状态，记录的是更新<strong>之前</strong>的值；</li></ul><blockquote><p>redo log 刷盘策略</p></blockquote><p>redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210626.png" alt="image-20220915172033879" style="zoom:67%;" /> <p><code>InnoDB</code> 存储引擎为 <code>redo log</code> 的刷盘策略提供了 <code>innodb_flush_log_at_trx_commit</code> 参数，它支持三种策略：</p><ul><li><strong>0</strong> ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作</li><li><strong>1</strong> ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）</li><li><strong>2</strong> ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache</li></ul><p><code>innodb_flush_log_at_trx_commit</code> 参数默认为 1 ，也就是说当事务提交时会调用 <code>fsync</code> 对 redo log 进行刷盘</p><p>另外，<code>InnoDB</code> 存储引擎有一个后台线程，每隔<code>1</code> 秒，就会把 <code>redo log buffer</code> 中的内容写到文件系统缓存（<code>page cache</code>），然后调用 <code>fsync</code> 刷盘</p><p>除了后台线程每秒<code>1</code>次的轮询操作，还有一种情况，当 <code>redo log buffer</code> 占用的空间即将达到 <code>innodb_log_buffer_size</code> 一半的时候，后台线程会主动刷盘。</p><p>下面是不同刷盘策略的流程图。</p><ul><li><p>innodb_flush_log_at_trx_commit=0</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210631.png" alt="image-20220915172736501" style="zoom:67%;" /><p> 为<code>0</code>时，如果<code>MySQL</code>挂了或宕机可能会有<code>1</code>秒数据的丢失。</p></li><li><p>innodb_flush_log_at_trx_commit=1</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210635.png" alt="image-20220915172514520" style="zoom: 67%;" /><p>为<code>1</code>时， 只要事务提交成功，<code>redo log</code>记录就一定在硬盘里，不会有任何数据丢失。</p><p>如果事务执行期间<code>MySQL</code>挂了或宕机，这部分日志丢了，但是事务并没有提交，所以日志丢了也不会有损失 </p></li><li><p>innodb_flush_log_at_trx_commit=2</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210640.png" alt="image-20220915172820371" style="zoom:67%;" /><p> 为<code>2</code>时， 只要事务提交成功，<code>redo log buffer</code>中的内容只写入文件系统缓存（<code>page cache</code>）。</p><p>如果仅仅只是<code>MySQL</code>挂了不会有任何数据丢失，但是宕机可能会有<code>1</code>秒数据的丢失。</p></li></ul><blockquote><p>redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？</p></blockquote><p>写入 redo log 的方式使用了追加操作， 所以磁盘操作是<strong>顺序写</strong>，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是<strong>随机写</strong>。</p><p>磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。</p><blockquote><p>日志文件组</p></blockquote><p>硬盘上存储的 <code>redo log</code> 日志文件不只一个，而是以一个<strong>日志文件组</strong>的形式出现的，每个的<code>redo</code>日志文件大小都是一样的。</p><p>它采用的是环形数组形式，从头开始写，写到末尾又回到头循环写</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210645.png" alt="img" style="zoom:67%;" /> <p>在个<strong>日志文件组</strong>中还有两个重要的属性，分别是 <code>write pos、checkpoint</code></p><ul><li><strong>write pos</strong> 是当前记录的位置，一边写一边后移</li><li><strong>checkpoint</strong> 是当前要擦除的位置，也是往后推移</li></ul><p>每次刷盘 <code>redo log</code> 记录到<strong>日志文件组</strong>中，<code>write pos</code> 位置就会后移更新。</p><p>每次 <code>MySQL</code> 加载<strong>日志文件组</strong>恢复数据时，会清空加载过的 <code>redo log</code> 记录，并把 <code>checkpoint</code> 后移更新。</p><p><code>write pos</code> 和 <code>checkpoint</code> 之间的还空着的部分可以用来写入新的 <code>redo log</code> 记录。</p><p>如果 <code>write pos</code> 追上 <code>checkpoint</code> ，表示<strong>日志文件组</strong>满了，这时候不能再写入新的 <code>redo log</code> 记录，<code>MySQL</code> 得停下来，清空一些记录，把 <code>checkpoint</code> 推进一下。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210650.png" alt="img" style="zoom:67%;" /> <h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p><code>redo log</code> 是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 <code>InnoDB</code> 存储引擎</p><p><code>binlog</code> 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于<code>MySQL Server</code> 层。</p><p><code>binlog</code>会记录所有涉及更新数据的逻辑操作，并且是顺序写（不会覆盖以前的日志）， 用于备份恢复、主从复制。</p><blockquote><h6 id="主从复制的实现"><a href="#主从复制的实现" class="headerlink" title="主从复制的实现"></a>主从复制的实现</h6></blockquote><p>MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。</p><p>这个过程一般是<strong>异步</strong>的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210655.png" alt="MySQL 主从复制过程" style="zoom:67%;" /> <ul><li>MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</li><li>从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。</li><li>从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。</li></ul><p>在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主）</p><p>MySQL 主从复制模型：</p><ul><li><strong>同步复制</strong>：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。实际不可用。</li><li><strong>异步复制</strong>（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。</li><li><strong>半同步复制</strong>：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种<strong>半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险</strong>。</li></ul><blockquote><h6 id="binlog写入机制"><a href="#binlog写入机制" class="headerlink" title="binlog写入机制"></a>binlog写入机制</h6></blockquote><p>事务执行过程中，先把日志写到<code>binlog cache</code>，事务提交的时候，再把<code>binlog cache</code>写到<code>binlog</code>文件中。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210700.png" alt="img"></p><h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p>在执行更新语句过程，会记录<code>redo log</code>与<code>binlog</code>两块日志，以基本的事务为单位，<code>redo log</code>在事务执行过程中可以不断写入，而<code>binlog</code>只有在提交事务时才写入，所以<code>redo log</code>与<code>binlog</code>的写入时机不一样</p><p>但<code>redo log</code>与<code>binlog</code>两份日志之间的逻辑可能不一致，例如执行过程中写完<code>redo log</code>日志后，<code>binlog</code>日志写期间发生了异常。</p><p>为了解决两份日志之间的逻辑一致问题，<code>InnoDB</code>存储引擎使用<strong>两阶段提交</strong>方案：将<code>redo log</code>的写入拆成了两个步骤<code>prepare</code>和<code>commit</code></p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317210705.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis</title>
      <link href="/2023/03/17/redis/"/>
      <url>/2023/03/17/redis/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis基础"><a href="#Redis基础" class="headerlink" title="Redis基础"></a>Redis基础</h2><p>redis是一个基于C语言开发的分布式高性能 KV 存储数据库，被广泛应用于缓存方向。</p><ul><li>Redis 基于内存，内存的访问速度是磁盘的上千倍；</li><li>Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用；</li><li>Redis 内置了多种优化过后的数据结构实现，性能非常高。</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211604.png" alt="why-redis-so-fast"> </p><p>redis的应用</p><ul><li>缓存：高性能（内存）+高并发（QPS）</li><li>分布式锁：基于 Redisson 来实现分布式锁</li><li>限流： Redis + Lua 脚本</li><li>消息队列：Redis Stream 类型和List类型的数据结构可以用来做消息队列。</li><li>复杂业务场景：通过 bitmap 统计活跃用户、通过 sorted set 维护排行榜。</li></ul><hr><h2 id="Redis数据结构"><a href="#Redis数据结构" class="headerlink" title="Redis数据结构"></a>Redis数据结构</h2><blockquote><p><a href="https://xiaolincoding.com/redis/data_struct/">小林coding</a></p></blockquote><ul><li><strong>5 种基础数据结构</strong> ：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。</li><li><strong>3 种特殊数据结构</strong> ：HyperLogLogs（基数统计）、Bitmap （位存储）、Geospatial (地理位置)。</li></ul><h3 id="基本数据结构"><a href="#基本数据结构" class="headerlink" title="基本数据结构"></a>基本数据结构</h3><h4 id="String（字符串）"><a href="#String（字符串）" class="headerlink" title="String（字符串）"></a>String（字符串）</h4> <img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211612.png" alt="img" style="zoom: 67%;" /><p>String 是一种二进制安全的数据结构，可以用来存储任何类型的数据比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。 </p><p>底层实现： int 和 SDS（简单动态字符串）</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211614.png" alt="img"> </p><p>应用场景</p><ul><li><p>需要存储常规数据的场景</p><ul><li>缓存 session、token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。</li><li>相关命令 ： <code>SET</code>、<code>GET</code>。</li></ul></li><li><p>需要计数的场景</p><ul><li>举例 ：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。</li><li>相关命令 ：<code>SET</code>、<code>GET</code>、 <code>INCR</code>、<code>DECR</code> 。</li></ul></li><li><p>分布式锁</p><ul><li>利用 <code>SETNX key value</code> 命令可以实现一个最简易的分布式锁（存在一些缺陷，通常不建议这样实现分布式锁）</li></ul></li></ul><h4 id="List（列表）"><a href="#List（列表）" class="headerlink" title="List（列表）"></a>List（列表）</h4><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211619.png" alt="img" style="zoom:67%;" /> <p>List 列表是简单的字符串列表，<strong>按照插入顺序排序</strong>，可以从头部或尾部向 List 列表添加元素。</p><p>底层实现：双向链表或压缩列表(但是在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表)</p><p>应用场景：</p><ul><li>信息流展示<ul><li>举例 ：最新文章、最新动态。</li><li>相关命令 ： <code>LPUSH</code>、<code>LRANGE</code>。</li></ul></li><li>消息队列<ul><li>消息保序：使用 <code>LPUSH</code> + <code>RPOP</code>；</li><li>阻塞读取：使用 <code>BRPOP</code>；</li><li>重复消息处理：生产者自行实现全局唯一 ID；</li><li>消息的可靠性：使用 <code>BRPOPLPUSH</code></li></ul></li></ul><h4 id="Hash（哈希）"><a href="#Hash（哈希）" class="headerlink" title="Hash（哈希）"></a>Hash（哈希）</h4><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211623.png" alt="img" style="zoom:67%;" /> <p>Hash 是一个键值对（key - value）集合，其中 value 的形式如： <code>value=[&#123;field1，value1&#125;，...&#123;fieldN，valueN&#125;]</code>。Hash 特别适合用于存储对象。</p><p>Hash 类型的底层数据结构是由<strong>压缩列表或哈希表</strong>实现的(在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。)</p><p>应用场景</p><ul><li>对象数据存储场景<ul><li>举例 ：用户信息、商品信息、文章信息、购物车信息。</li><li>相关命令 ：<code>HSET</code> （设置单个字段的值）、<code>HMSET</code>（设置多个字段的值）、<code>HGET</code>（获取单个字段的值）、<code>HMGET</code>（获取多个字段的值）。</li></ul></li></ul><blockquote><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>String 还是 Hash 存储对象数据更好呢？</p><ul><li>String 存储的是序列化后的对象数据，存放的是整个对象。相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有<strong>多层嵌套的对象</strong>时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。</li><li>Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中<strong>某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息</strong>，Hash 就非常适合。</li></ul><p>在绝大部分情况，我们建议使用 String 来存储对象数据即可！</p></blockquote><blockquote><h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><p>购物车信息用 String 还是 Hash 存储更好呢?</p><p>由于购物车中的商品频繁修改和变动，购物车信息建议使用 Hash 存储：</p><ul><li>用户 id 为 key</li><li>商品 id 为 field，商品数量为 value</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211625.png" alt="Hash维护简单的购物车信息"> </p></blockquote><h4 id="Set（集合）"><a href="#Set（集合）" class="headerlink" title="Set（集合）"></a>Set（集合）</h4> <img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211627.png" alt="img" style="zoom:67%;" /><p>Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。</p><p>Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集，以及判断某个元素是否在集合中；</p><p>Set 类型的底层数据结构是由<strong>哈希表或整数集合</strong>实现的：</p><p>应用场景</p><ul><li><p>需要存放的数据不能重复的场景</p><ul><li>举例：网站 UV 统计（数据量巨大的场景还是 <code>HyperLogLog</code>更适合一些）、文章点赞、动态点赞等场景。</li><li>相关命令：<code>SCARD</code>（获取集合数量） 。</li></ul></li><li><p>需要获取多个数据源交集、并集和差集的场景</p><ul><li>举例 ：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集） 、订阅号推荐（差集+交集） 等场景。</li><li>相关命令：<code>SINTER</code>（交集）、<code>SINTERSTORE</code> （交集）、<code>SUNION</code> （并集）、<code>SUNIONSTORE</code>（并集）、<code>SDIFF</code>（差集）、<code>SDIFFSTORE</code> （差集）。</li></ul></li><li><p>需要随机获取数据源中的元素的场景</p><ul><li>举例 ：抽奖系统、随机。</li><li>相关命令：<code>SPOP</code>（随机获取集合中的元素并移除，适合不允许重复中奖的场景）、<code>SRANDMEMBER</code>（随机获取集合中的元素，适合允许重复中奖的场景）。</li></ul></li></ul><h4 id="Zset（有序集合）"><a href="#Zset（有序集合）" class="headerlink" title="Zset（有序集合）"></a>Zset（有序集合）</h4><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211632.png" alt="img" style="zoom:67%;" /> <p>Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有元素值，一个是排序值。</p><p>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的</p><p>应用场景</p><ul><li><p>需要随机获取数据源中的元素根据某个权重进行排序的场景</p><ul><li>举例 ：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。</li><li>相关命令 ：<code>ZRANGE</code> (从小到大排序) 、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li></ul></li><li><p>需要存储的数据有优先级或者重要程度的场景 比如优先级任务队列。</p><ul><li>举例 ：优先级任务队列。</li><li>相关命令 ：<code>ZRANGE</code> (从小到大排序) 、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li></ul></li></ul><h3 id="特殊数据结构"><a href="#特殊数据结构" class="headerlink" title="特殊数据结构"></a>特殊数据结构</h3><h4 id="BitMap（位图）"><a href="#BitMap（位图）" class="headerlink" title="BitMap（位图）"></a>BitMap（位图）</h4><p>Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行<code>0|1</code>的设置，表示某个元素的值或者状态，<strong>特别适合一些数据量大且使用二值统计的场景</strong>。</p><p>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211636.png" alt="img" style="zoom:67%;" />  <p>应用场景：</p><ul><li>需要保存状态信息（0/1 即可表示）的场景。<ul><li>举例 ：用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。</li><li>相关命令 ：<code>SETBIT</code>、<code>GETBIT</code>、<code>BITCOUNT</code>、<code>BITOP</code>。</li></ul></li></ul><h4 id="HyperLogLog（基数计数概率算法）"><a href="#HyperLogLog（基数计数概率算法）" class="headerlink" title="HyperLogLog（基数计数概率算法）"></a>HyperLogLog（基数计数概率算法）</h4><p>是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。</p><p>简单来说 HyperLogLog <strong>提供不精确的去重计数</strong>。</p><p>Redis 提供的 HyperLogLog 占用空间非常非常小，只需要 12k 的空间就能存储接近<code>2^64</code>个不同元素</p><p>应用场景：</p><ul><li>数量量巨大（百万、千万级别以上）的计数场景<ul><li>举例 ：热门网站每日/每周/每月访问 ip 数统计、热门帖子 uv 统计、</li><li>相关命令 ：<code>PFADD</code>、<code>PFCOUNT</code> 。</li></ul></li></ul><h4 id="Geospatial-index（地理空间索引）"><a href="#Geospatial-index（地理空间索引）" class="headerlink" title="Geospatial index（地理空间索引）"></a>Geospatial index（地理空间索引）</h4><p>Geospatial index（地理空间索引，简称 GEO） 主要用于存储地理位置信息，基于 Sorted Set 实现。</p><p>通过 GEO 我们可以轻松实现两个位置距离的计算、获取指定位置附近的元素等功能。</p><p>应用场景：</p><ul><li>需要管理使用地理空间数据的场景<ul><li>举例：附近的人。</li><li>相关命令: <code>GEOADD</code>、<code>GEORADIUS</code>、<code>GEORADIUSBYMEMBER</code> 。</li></ul></li></ul><hr><h2 id="Redis-线程模型"><a href="#Redis-线程模型" class="headerlink" title="Redis 线程模型"></a>Redis 线程模型</h2><p>Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用，这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。</p><ul><li>文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。</li><li>当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211639.png" alt="img"> </p><p>对于读写命令来说，Redis 一直是单线程模型。不过，在 </p><ul><li><p>Redis  2.6 版本之后，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；</p></li><li><p>Redis 4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作</p></li><li><p>Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）</p></li></ul><p>redis为什么使用单线程？</p><ul><li><p>单线程编程容易并且更容易维护；</p></li><li><p>Redis 的性能瓶颈不在 CPU ，主要在内存和网络；</p><ul><li><p>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构</p></li><li><p>单线程采用 I/O 多路复用机制可以处理大量的客户端 Socket 请求</p></li></ul></li><li><p>多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。</p></li></ul><hr><h2 id="redis内存管理"><a href="#redis内存管理" class="headerlink" title="redis内存管理"></a>redis内存管理</h2><h3 id="redis过期删除策略"><a href="#redis过期删除策略" class="headerlink" title="redis过期删除策略"></a>redis过期删除策略</h3><p>一般情况下，我们设置保存的缓存数据的时候都会设置一个过期时间，可以有助于缓解内存的消耗。</p><p>Redis 自带了给缓存数据设置过期时间的功能，比如：</p><pre class=" language-sh"><code class="language-sh">exp key 60 # 数据在 60s 后过期setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)ttl key # 查看数据还有多久过期</code></pre><p>每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个<strong>过期字典</strong>（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。</p><p>过期字典存储在 redisDb 结构中，如下：</p><pre class=" language-c"><code class="language-c"><span class="token keyword">typedef</span> <span class="token keyword">struct</span> redisDb <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    dict <span class="token operator">*</span>dict<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/* 数据库键空间，存放着所有的键值对 */</span>    dict <span class="token operator">*</span>expires<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">/* 键的过期时间 */</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> redisDb<span class="token punctuation">;</span></code></pre><p>过期字典数据结构结构如下：</p><ul><li>过期字典的 key 是一个指针，指向某个键对象；</li><li>过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211643.png" alt="img"></p><p>当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：</p><ul><li>如果不在，则正常读取键值；</li><li>如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。</li></ul><p>Redis 使用的过期删除策略是「<strong>惰性删除+定期删除</strong>」这两种策略配和使用</p><ul><li><p><strong>惰性删除</strong> ：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。</p></li><li><p><strong>定期删除</strong> ：每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。这样对内存友好，并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。</p></li></ul><h3 id="redis内存淘汰机制"><a href="#redis内存淘汰机制" class="headerlink" title="redis内存淘汰机制"></a>redis内存淘汰机制</h3><p>当大量过期key堆积在内存里， Redis 的运行内存会达到了某个阀值，触发内存淘汰机制。</p><p>不进行数据淘汰</p><ol><li><strong>noeviction</strong>（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。</li></ol><p>在设置了过期时间的数据中进行淘汰</p><ol start="2"><li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；</li><li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。</li><li><strong>volatile-lru</strong>（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；</li><li><strong>volatile-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</li></ol><p>在所有数据范围内进行淘汰：</p><ol start="6"><li><strong>allkeys-random</strong>：随机淘汰任意键值;</li><li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；</li><li><strong>allkeys-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</li></ol><blockquote><p>Redis 是如何实现 LRU 算法的？</p></blockquote><p>传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。</p><p>Redis 实现的是一种<strong>近似 LRU 算法</strong>，目的是为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。</p><p>当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，它是随机取 5 个值（此值可配置），然后<strong>淘汰最久没有使用的那个</strong>。</p><blockquote><p>Redis 是如何实现 LFU 算法的？</p></blockquote><p>LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息，根据数据访问次数来淘汰数据的，</p><h2 id="Redis-持久化机制"><a href="#Redis-持久化机制" class="headerlink" title="Redis 持久化机制"></a>Redis 持久化机制</h2><p>Redis 共有三种数据持久化的方式：</p><ul><li><p><strong>AOF 日志</strong>：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；</p><ul><li>AOF的数据安全性较高，可以实时或者秒级持久化数据，支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据）</li><li>AOF 以一种易于理解和解析的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。</li></ul></li><li><p><strong>RDB 快照</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘；</p><ul><li>RDB 文件很小，适合做数据的备份，灾难恢复。</li><li>使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。</li></ul></li><li><p><strong>混合持久化方式</strong>：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；</p><ul><li><p>在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p></li><li><p>这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。</p></li></ul></li></ul><h3 id="RDB-持久化"><a href="#RDB-持久化" class="headerlink" title="RDB 持久化"></a>RDB 持久化</h3><p>Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。</p><p>Redis 提供了两个命令来生成 RDB 快照文件：</p><ul><li><code>save</code> : 主线程执行，会阻塞主线程；</li><li><code>bgsave</code> : 子线程执行，不会阻塞主线程，默认选项。</li></ul><h3 id="AOF-持久化"><a href="#AOF-持久化" class="headerlink" title="AOF 持久化"></a>AOF 持久化</h3><p>开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到内存缓存 <code>server.aof_buf</code> 中，然后再根据 <code>appendfsync</code> 配置来决定何时将其同步到硬盘中的 AOF 文件。</p><blockquote><p>AOF 写回策略有几种？</p></blockquote><p>在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：</p><pre class=" language-bash"><code class="language-bash">appendfsync always    <span class="token comment" spellcheck="true">#每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度</span>appendfsync everysec  <span class="token comment" spellcheck="true">#每秒钟同步一次，显式地将多个写命令同步到硬盘</span>appendfsync no        <span class="token comment" spellcheck="true">#让操作系统决定何时进行同步</span></code></pre><p>为了兼顾数据和写入性能，用户可以考虑 <code>appendfsync everysec</code> 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。</p><blockquote><p>为什么先执行命令，再把数据写入日志呢？</p></blockquote><p>关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复），而 Redis AOF 持久化机制是在执行完命令之后再记录日志。</p><p>好处</p><ul><li>避免额外的检查开销，AOF 记录日志不会对命令进行语法检查；</li><li>在命令执行完之后再记录，不会阻塞当前的命令执行。</li></ul><p>风险</p><ul><li>如果刚执行完命令 Redis 就宕机会导致对应的修改丢失；</li><li>可能会阻塞后续其他命令的执行（AOF 记录日志是在 Redis 主线程中进行的）。</li></ul><blockquote><p>AOF 日志过大，会触发什么机制？</p></blockquote><p>AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。</p><p>当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。</p><p>AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。</p><h2 id="Redis缓存"><a href="#Redis缓存" class="headerlink" title="Redis缓存"></a>Redis缓存</h2><h3 id="常见缓存问题"><a href="#常见缓存问题" class="headerlink" title="常见缓存问题"></a>常见缓存问题</h3><h4 id="缓存雪崩：避免缓存的集中失效"><a href="#缓存雪崩：避免缓存的集中失效" class="headerlink" title="缓存雪崩：避免缓存的集中失效"></a>缓存雪崩：避免缓存的集中失效</h4><p>当大量缓存数据在同一时间过期（失效）时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211647.png" alt="image-20221106151341609"> </p><p>对于缓存雪崩问题，我们可以采用两种方案解决。</p><ul><li>将缓存失效时间随机打散： 批量加载的场景，将过期时间在一个固定时间段内以毫秒级别进行随机打散，比如本来要设置每条记录过期时间为5分钟，则批量加载的时候可以设置过期时间为5~10分钟之间的任意一个毫秒数。</li><li>互斥锁：当业务线程在处理用户请求时，如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存</li><li>双 key 策略：我们对缓存数据可以使用两个 key，一个是主 key，会设置过期时间，一个是备 key，不会设置过期，当业务线程访问不到「主 key 」的缓存数据时，就直接返回「备 key 」的缓存数据，然后在更新缓存的时候，同时更新「主 key 」和「备 key 」的数据。</li></ul><h4 id="缓存击穿：有效的冷数据预热加载机制"><a href="#缓存击穿：有效的冷数据预热加载机制" class="headerlink" title="缓存击穿：有效的冷数据预热加载机制"></a>缓存击穿：有效的冷数据预热加载机制</h4><p>如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是<strong>缓存击穿</strong>的问题。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211651.png" alt="image-20221106151955154"> </p><p><code>缓存击穿</code>和前面提到的<code>缓存雪崩</code>产生的原因其实很相似。<strong>区别点</strong>在于：</p><ul><li>缓存雪崩是<strong>大面积的缓存失效</strong>导致大量请求涌入数据库。</li><li>缓存击穿是<strong>少量缓存失效</strong>的时候恰好失效的数据<strong>遭遇大并发量的请求</strong>，导致这些请求全部涌入数据库中。</li></ul><p>对于缓存击穿问题，我们可以采用两种方案解决。</p><ul><li>缓存续期：可以为热点数据设置一个过期时间<strong>续期</strong>的操作，比如每次请求的时候自动将过期时间续期一下。</li><li>分布式锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态）：当缓存不可用时，仅<code>持锁的线程</code>负责从数据库中查询数据并写入缓存中，其余请求重试时先尝试从缓存中获取数据，避免所有的并发请求全部同时打到数据库上。</li></ul><blockquote><p>恶意程序（爬虫）一直在刷历史数据，容易将内存中的热点数据变为历史数据，导致真正的用户请求被打到数据库层。这时该怎么设计缓存？</p></blockquote><p>缓存指定时间段内的数据（比如最近1年），且<strong>数据不存在时从DB获取内容之后也不会回写到缓存</strong>中。同时设计冷数据加热机制，可以约定同一秒内对某条冷数据的请求超过<code>10次</code>，则将此条冷数据加热作为<strong>临时热点</strong>数据存入缓存，设定缓存过期时间为30天（一般一个陈年八卦一个月足够消停下去了）。通过这样的机制，来解决冷数据的突然窜热对系统带来的不稳定影响。</p><h4 id="缓存穿透：合理的防身自保手段"><a href="#缓存穿透：合理的防身自保手段" class="headerlink" title="缓存穿透：合理的防身自保手段"></a>缓存穿透：合理的防身自保手段</h4><p>当用户访问的数据，<strong>既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是<strong>缓存穿透</strong>的问题。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211654.png" alt="image-20221106153912931"> </p><p><code>缓存穿透</code>的情况往往出现在一些外部干扰或者攻击情景中，比如<strong>外部爬虫</strong>、比如<strong>黑客攻击</strong>等等。</p><p>应对缓存穿透的方案，常见的方案有三种。</p><ul><li><strong>非法请求的限制</strong>：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</li><li><strong>设置空值或者默认值</strong>：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。</li><li><strong>使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在</strong>：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。</li></ul><h3 id="常见缓存更新策略"><a href="#常见缓存更新策略" class="headerlink" title="常见缓存更新策略"></a>常见缓存更新策略</h3><ul><li><p>Cache Aside（旁路型缓存）策略；（实际开发中，Redis 和 MySQL 的更新策略）</p><p>在<strong>旁路型缓存</strong>模式中，业务自行负责与缓存以及数据库之间的交互，可以<strong>自由决定缓存未命中场景的处理策略</strong>，更加契合大部分业务场景的定制化诉求。</p><p>由于业务模块自行实现缓存与数据库之间的数据写入与更新的逻辑，实际实现的时候需要注意下在<strong>高并发</strong>场景的<code>数据一致性</code>问题，以及可能会出现的<code>缓存击穿</code>、<code>缓存穿透</code>、<code>缓存雪崩</code>等问题的防护。</p></li><li><p>穿透型策略；</p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211657.png" alt="image-20221106155437477" style="zoom:80%;" /> </li><li><p>异步型缓存；</p></li></ul><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211659.png" alt="image-20221106155603860" style="zoom:90%;" /> <h4 id="缓存的数据一致性"><a href="#缓存的数据一致性" class="headerlink" title="缓存的数据一致性"></a>缓存的数据一致性</h4><p>对于基于<strong>旁路型缓存</strong>的大部分业务而言，数据更新操作，一般可以组合出几种不同的处理策略：</p><ul><li>先更新缓存，再更新数据库</li><li>先更新数据库， 再更新缓存</li><li>先删除缓存，再更新数据库</li><li>先更新数据库，再删除缓存</li></ul><p>对于一些<code>读多写少</code>、写操作并发量不是特别大且对一致性要求<em>不是特别高</em>的情况下，可以采用<strong>数据库事务（高隔离级别） + 先更新数据库再更新/删除缓存</strong>的方式来达到数据一致的诉求。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211702.png" alt="image-20221106160235183"> </p><p>对于并发要求较高、且数据一致性要求较好的时候，推荐选择<strong>先更新数据库，再删除缓存，并结合删除重试 + 补偿逻辑 + 缓存过期TTL等综合手段</strong>。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317211704.png" alt="image-20221106160549940"> </p><h2 id="Redis-实战"><a href="#Redis-实战" class="headerlink" title="Redis 实战"></a>Redis 实战</h2><h3 id="redis事务"><a href="#redis事务" class="headerlink" title="redis事务"></a>redis事务</h3><ul><li><p>redis事务不提供<strong>提供回滚机制</strong>，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。</p></li><li><p>redis 事务并不一定保证原子性，事务执行过程中，如果命令入队时没报错，而事务提交后，实际执行时报错了，正确的命令依然可以正常执行，</p></li></ul><h3 id="redis-bigkey"><a href="#redis-bigkey" class="headerlink" title="redis bigkey"></a>redis bigkey</h3><p>如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 bigkey。</p><ul><li>String 类型的值大于 10 KB；</li><li>Hash、List、Set、ZSet 类型的元素的个数超过 5000个；</li></ul><p>bigkey的影响？</p><ul><li>客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li><li>引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li><li>阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li><li>内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li></ul><p>如何发现bigkey？</p><ul><li><p>使用 Redis 自带的 <code>--bigkeys</code> 参数来查找。</p></li><li><p>使用 RdbTools 工具查找大 key</p></li></ul><p>如何删除big key？</p><ul><li>分批次删除</li><li><code>unlink</code> 命令异步删除（Redis 4.0版本以上）</li></ul><h3 id="redis实现延迟队列"><a href="#redis实现延迟队列" class="headerlink" title="redis实现延迟队列"></a>redis实现延迟队列</h3><p>延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：</p><ul><li>在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；</li><li>打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；</li><li>点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单</li></ul><p>在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。</p><p>用多个线程轮询Zset获取到期的任务进行处理，以此来实现延迟消息队列等，步骤如下：</p><ol><li>利用 <code>zadd</code> 向集合中插入元素，以元素的时间戳（超时时间）作为 score</li><li>利用 <code>zrangebyscore</code> 以 <code>0 &lt; score &lt;= 当前时间戳</code> 进行获取需要处理的元素</li><li>当有满足的条件的元素, 先删除<code>zrem</code>该元素（保证不被其他进程取到），再进行业务逻辑处理；</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络</title>
      <link href="/2023/03/17/ji-suan-ji-wang-luo/"/>
      <url>/2023/03/17/ji-suan-ji-wang-luo/</url>
      
        <content type="html"><![CDATA[<h2 id="分层模型"><a href="#分层模型" class="headerlink" title="分层模型"></a>分层模型</h2><h3 id="OSI-七层模型"><a href="#OSI-七层模型" class="headerlink" title="OSI 七层模型"></a>OSI 七层模型</h3><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170414.png" alt="img"> </p><h3 id="TCP-IP-四层模型"><a href="#TCP-IP-四层模型" class="headerlink" title="TCP/IP 四层模型"></a>TCP/IP 四层模型</h3><ol><li>应用层：HTTP （超文本传输协议）DHCP （动态主机配置）DNS （域名系统）FTP（文件传输协议）电子邮件协议（SMTP、POP3、IMAP）</li><li>传输层：TCP （传输控制协议） UDP（用户数据报协议）</li><li>网络层：IP （网际协议） ARP （地址解析协议）</li><li>网络接口层</li></ol><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><h3 id="HTTP-状态码"><a href="#HTTP-状态码" class="headerlink" title="HTTP 状态码"></a>HTTP 状态码</h3><p><code>1xx</code> 类状态码属于<strong>提示信息</strong>，是协议处理中的一种中间状态，实际用到的比较少。</p><p><code>2xx</code> 类状态码表示服务器<strong>成功</strong>处理了客户端的请求，也是我们最愿意看到的状态。</p><ul><li>「<strong>200 OK</strong>」是最常见的成功状态码，表示一切正常。如果是非 <code>HEAD</code> 请求，服务器返回的响应头都会有 body 数据。</li><li>「<strong>204 No Content</strong>」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。</li><li>「<strong>206 Partial Content</strong>」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。</li></ul><p><code>3xx</code> 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是<strong>重定向</strong>。</p><ul><li>「<strong>301 Moved Permanently</strong>」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。</li><li>「<strong>302 Found</strong>」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。</li></ul><p>301 和 302 都会在响应头里使用字段 <code>Location</code>，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。</p><ul><li>「<strong>304 Not Modified</strong>」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。</li></ul><p><code>4xx</code> 类状态码表示客户端发送的<strong>报文有误</strong>，服务器无法处理，也就是错误码的含义。</p><ul><li>「<strong>400 Bad Request</strong>」表示客户端请求的报文有错误，但只是个笼统的错误。</li><li>「<strong>403 Forbidden</strong>」表示服务器禁止访问资源，并不是客户端的请求出错。</li><li>「<strong>404 Not Found</strong>」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。</li></ul><p><code>5xx</code> 类状态码表示客户端请求报文正确，但是<strong>服务器处理时内部发生了错误</strong>，属于服务器端的错误码。</p><ul><li>「<strong>500 Internal Server Error</strong>」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。</li><li>「<strong>501 Not Implemented</strong>」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。</li><li>「<strong>502 Bad Gateway</strong>」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。</li><li>「<strong>503 Service Unavailable</strong>」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思</li></ul><h3 id="HTTP报文"><a href="#HTTP报文" class="headerlink" title="HTTP报文"></a>HTTP报文</h3><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170435.png" alt="HTTP 请求报文结构"> </p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170444.png" alt="HTTP 响应报文结构"> </p><p>常见字段</p><ul><li><em>Host</em> 字段：客户端发送请求时，用来指定服务器的域名。</li><li><em>Content-Length 字段</em>：服务器在返回数据时，会有 <code>Content-Length</code> 字段，表明本次回应的数据长度。</li><li><em>Connection 字段</em>：<code>Connection</code> 字段最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用</li><li><em>Content-Type 字段</em>：<code>Content-Type</code> 字段用于服务器回应时，告诉客户端，本次数据是什么格式。</li><li><em>Content-Encoding 字段</em>：<code>Content-Encoding</code> 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式</li></ul><p>请求方法</p><ul><li>GET：从服务器获取指定的资源</li><li>POST：根据请求负荷（报文body）对指定的资源做出处理</li><li>PUT：从客户端向服务器传送的数据取代指定的文档的内容</li><li>DELETE：请求服务器删除指定的资源。</li></ul><h3 id="HTTP-缓存"><a href="#HTTP-缓存" class="headerlink" title="HTTP 缓存"></a>HTTP 缓存</h3><p>对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都缓存在本地，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了。</p><p>HTTP 缓存有两种实现方式，分别是强制缓存和协商缓存</p><p><strong>强制缓存</strong></p><p>强制缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170452.png" alt="img"> </p><p>强制缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：</p><ul><li><code>Cache-Control</code>， 是一个相对时间；</li><li><code>Expires</code>，是一个绝对时间；</li></ul><p>具体的实现流程如下：</p><ol><li>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；</li><li>浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器；</li><li>服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。</li></ol><p><strong>协商缓存</strong></p><p>通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存（304响应码）</p><blockquote><p>协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。</p></blockquote><p>协商缓存可以基于两种头部来实现。</p><p>第一种：请求头部中的 <code>If-Modified-Since</code> 字段与响应头部中的 <code>Last-Modified</code> 字段实现，这两个字段的意思是：</p><ul><li>响应头部中的 <code>Last-Modified</code>：标示这个响应资源的最后修改时间；</li><li>请求头部中的 <code>If-Modified-Since</code>：当资源过期了，浏览器发现响应头中具有 Last-Modified 声明，则再次向服务器发起请求时，会将请求头 If-Modified-Since  值设置为 Last-Modified 的值。服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。</li></ul><p>第二种：请求头部中的 <code>If-None-Match</code> 字段与响应头部中的 <code>ETag</code> 字段，这两个字段的意思是：</p><ul><li>响应头部中 <code>Etag</code>：唯一标识响应资源；</li><li>请求头部中的 <code>If-None-Match</code>：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。</li></ul><p>具体实现流程</p><ul><li><p>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；</p></li><li><p>当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：</p><ul><li>如果没有过期，则直接使用本地缓存；</li><li>如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；</li></ul></li><li><p>服务器再次收到请求后，</p><p>会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较</p><ul><li>如果值相等，则返回 304 Not Modified，不会返回资源；</li><li>如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；</li></ul></li><li><p>如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源</p></li></ul><h3 id="HTTP-与-HTTPS"><a href="#HTTP-与-HTTPS" class="headerlink" title="HTTP 与 HTTPS"></a>HTTP 与 HTTPS</h3><p>HTTP 与 HTTPS 的区别</p><ul><li>端口号 ：HTTP 默认是 80，HTTPS 默认是 443。</li><li>URL 前缀 ：HTTP 的 URL 前缀是 <code>http://</code>，HTTPS 的 URL 前缀是 <code>https://</code>。</li><li>安全性和资源消耗 ： HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 <code>SSL/TLS</code> 之上的 HTTP 协议，<code>SSL/TLS</code> 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。</li></ul><p>SSL/TLS 基本流程</p><ul><li>客户端向服务器索要并验证服务器的公钥。</li><li>双方协商生产「会话秘钥」。</li><li>双方采用「会话秘钥」进行加密通信。</li></ul><p>SSL/TLS 工作原理</p><p>混合加密</p><p>HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式，实现信息的机密性：</p><ul><li>在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。</li><li>在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。</li></ul><p>数字证书</p><p>将服务器公钥放在CA （数字证书认证机构）数颁布的数字证书中，利用数字签名技术防止证书被伪造，确保服务器公钥的可信</p><p>摘要算法 + 数字签名</p><ul><li>摘要算法：使用哈希函数来计算出内容的哈希值，保证传输的内容不被篡改</li><li>数字签名：对内容的哈希值，私钥加密，公钥解密，来确认消息的身份</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170503.jpeg" alt="数子证书工作流程">  </p><h3 id="HTTP-1-0-vs-HTTP-1-1"><a href="#HTTP-1-0-vs-HTTP-1-1" class="headerlink" title="HTTP 1.0 vs HTTP 1.1"></a>HTTP 1.0 vs HTTP 1.1</h3><p><strong>连接方式</strong> : HTTP 1.0 为短连接，HTTP 1.1 支持长连接。</p><p><strong>状态响应码</strong> : HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，<code>100 (Continue)</code>——在请求大资源前的预热请求，<code>206 (Partial Content)</code>——范围请求的标识码，<code>409 (Conflict)</code>——请求与当前资源的规定冲突，<code>410 (Gone)</code>——资源已被永久转移，而且没有任何已知的转发地址。</p><p><strong>缓存处理</strong> : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。</p><p><strong>带宽优化及网络连接的使用</strong> :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</p><p><strong>Host头处理</strong> : HTTP/1.1在请求头中加入了<code>Host</code>字段</p><h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>TCP：面向连接的，可靠的，基于字节流，一般用于FTP 文件传输，HTTP / HTTPS。</p><p>UDP：无连接的，尽力分发的，基于报文，一般用于即时通信，比如： 语音、 视频 、直播等。</p><h3 id="TCP-头部格式"><a href="#TCP-头部格式" class="headerlink" title="TCP 头部格式"></a>TCP 头部格式</h3><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170510.png" alt="TCP 头格式"></p><p>序列号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。</p><p>确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。</p><p>控制位：</p><ul><li>ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。</li><li>RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。</li><li>SYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。</li><li>FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段</li></ul><h3 id="TCP-连接建立"><a href="#TCP-连接建立" class="headerlink" title="TCP 连接建立"></a>TCP 连接建立</h3><h4 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h4><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170516.png" alt="TCP 三次握手"></p><ol><li>一开始，客户端和服务端都处于 <code>CLOSE</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态</li><li>客户端会随机初始化序号（<code>client_isn</code>），将此序号置于 TCP 首部的「序号」字段中，同时把 <code>SYN</code> 标志位置为 <code>1</code>，表示 <code>SYN</code> 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 <code>SYN-SENT</code> 状态。</li><li>服务端收到客户端的 <code>SYN</code> 报文后，首先服务端也随机初始化自己的序号（<code>server_isn</code>），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 <code>client_isn + 1</code>, 接着把 <code>SYN</code> 和 <code>ACK</code> 标志位置为 <code>1</code>。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 <code>SYN-RCVD</code> 状态。</li><li>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 <code>ACK</code> 标志位置为 <code>1</code> ，其次「确认应答号」字段填入 <code>server_isn + 1</code> ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 <code>ESTABLISHED</code> 状态。</li><li>服务端收到客户端的应答报文后，也进入 <code>ESTABLISHED</code> 状态。</li></ol><h4 id="为什么要三次握手？"><a href="#为什么要三次握手？" class="headerlink" title="为什么要三次握手？"></a>为什么要三次握手？</h4><p>双方确认自己与对方的发送与接收是正常的。</p><p>第一次握手丢失了，客户端就会触发「超时重传」机制，重传 SYN 报文，而且重传的 SYN 报文的序列号都是一样的。</p><p>第二次握手丢失了，客户端就会触发超时重传机制，重传 SYN 报文，服务端也会触发超时重传机制，重传 SYN-ACK 报文。</p><p>第三次握手丢失了，服务端会触发超时重传机制，重传 SYN-ACK 报文。</p><blockquote><p><strong>ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文</strong>。</p></blockquote><h4 id="SYN-攻击"><a href="#SYN-攻击" class="headerlink" title="SYN 攻击"></a>SYN 攻击</h4><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p><ul><li>半连接队列，也称 SYN 队列；</li><li>全连接队列，也称 accept 队列；</li></ul><p>工作流程</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170522.png" alt="正常流程"> </p><ul><li>当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；</li><li>接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；</li><li>服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；</li><li>应用通过调用 <code>accpet()</code> socket 接口，从「 Accept 队列」取出连接对象。</li></ul><p>SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。</p><h3 id="TCP连接断开"><a href="#TCP连接断开" class="headerlink" title="TCP连接断开"></a>TCP连接断开</h3><h4 id="TCP-四次挥手"><a href="#TCP-四次挥手" class="headerlink" title="TCP 四次挥手"></a>TCP 四次挥手</h4><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170527.png" alt="客户端主动关闭连接 —— TCP 四次挥手"> </p><ol><li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code>FIN</code> 标志位被置为 <code>1</code> 的报文，也即 <code>FIN</code> 报文，之后客户端进入 <code>FIN_WAIT_1</code> 状态。</li><li>服务端收到该报文后，就向客户端发送 <code>ACK</code> 应答报文，接着服务端进入 <code>CLOSE_WAIT</code> 状态。</li><li>客户端收到服务端的 <code>ACK</code> 应答报文后，之后进入 <code>FIN_WAIT_2</code> 状态。</li><li>等待服务端处理完数据后，也向客户端发送 <code>FIN</code> 报文，之后服务端进入 <code>LAST_ACK</code> 状态。</li><li>客户端收到服务端的 <code>FIN</code> 报文后，回一个 <code>ACK</code> 应答报文，之后进入 <code>TIME_WAIT</code> 状态</li><li>服务端收到了 <code>ACK</code> 应答报文后，就进入了 <code>CLOSE</code> 状态，至此服务端已经完成连接的关闭。</li><li>客户端在经过 <code>2MSL</code> 一段时间后，自动进入 <code>CLOSE</code> 状态，至此客户端也完成连接的关闭</li></ol><h4 id="为什么挥手需要四次？"><a href="#为什么挥手需要四次？" class="headerlink" title="为什么挥手需要四次？"></a>为什么挥手需要四次？</h4><ul><li>关闭连接时，客户端向服务端发送 <code>FIN</code> 时，仅仅表示客户端不再发送数据了但是还能接收数据。</li><li>服务端收到客户端的 <code>FIN</code> 报文时，先回一个 <code>ACK</code> 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 <code>FIN</code> 报文给客户端来表示同意现在关闭连接。</li></ul><h4 id="为什么-TIME-WAIT-等待的时间是-2MSL？"><a href="#为什么-TIME-WAIT-等待的时间是-2MSL？" class="headerlink" title="为什么 TIME_WAIT 等待的时间是 2MSL？"></a>为什么 TIME_WAIT 等待的时间是 2MSL？</h4><p>第四次挥手时，客户端发送给服务器的 ACK 有可能丢失，如果服务端因为某些原因而没有收到 ACK 的话，服务端就会重发 FIN，如果客户端在 2*MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，防止 Server 没有收到 ACK 而不断重发 FIN。</p><blockquote><p><strong>MSL(Maximum Segment Lifetime)</strong> : 报文最大生存时间，2MSL 就是一个发送和一个回复所需的最大时间。如果直到 2MSL，Client 都没有再次收到 FIN，那么 Client 推断 ACK 已经被成功接收，则结束 TCP 连接</p></blockquote><h4 id="为什么需要-TIME-WAIT-状态"><a href="#为什么需要-TIME-WAIT-状态" class="headerlink" title="为什么需要 TIME_WAIT 状态"></a>为什么需要 TIME_WAIT 状态</h4><ul><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；</li><li>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；</li></ul><h3 id="TCP-传输可靠性保障"><a href="#TCP-传输可靠性保障" class="headerlink" title="TCP 传输可靠性保障"></a>TCP 传输可靠性保障</h3><p>TCP 是通过序列号、确认应答、超时重传，流量控制，拥塞控制等机制实现可靠性传输的。</p><h4 id="重传机制"><a href="#重传机制" class="headerlink" title="重传机制"></a>重传机制</h4><h5 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h5><p>在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据</p><p>TCP 会在以下两种情况发生超时重传：</p><ul><li>数据包丢失</li><li>确认应答丢失</li></ul><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170533.jpg" alt="超时重传的两种情况"> </p><blockquote><p>超时时间应该设置为多少呢？</p><p><strong>超时重传时间 RTO 的值应该略大于报文往返 RTT 的值</strong>。</p></blockquote><p>如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是超时间隔加倍。</p><h5 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h5><p>当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170541.jpg" alt="快速重传机制"> </p><h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p>TCP 利用滑动窗口实现流量控制，让「发送方」根据「接收方」的实际接收能力控制发送的数据量</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170548.png" alt="image-20230306232231678"> </p><p>发送窗口</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170553.png" alt="image-20230306232547896">  </p><p>接受窗口</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170558.png" alt="image-20230306232611877"> </p><h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h4><p>拥塞控制目的就是避免「发送方」的数据填满整个网络。</p><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170605.png" alt="TCP的拥塞控制"> </p><ul><li><p>慢启动（指数增长）</p><p>当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1</p></li><li><p>拥塞避免（线性增长）</p><p>当拥塞窗口 cwnd 「超过」慢启动门限 ssthresh 就会进入拥塞避免算法</p><p>每当收到一个 ACK 时，cwnd 增加 1/cwnd</p></li><li><p>拥塞发生</p><p>发生超时重传的拥塞发生算法：ssthresh 设为 cwnd/2，cwnd 重置为 初始值，进入慢启动</p><p>发生快速重传的拥塞发生算法：ssthresh = cwnd/2，cwnd = ssthresh+3，进入快速恢复</p></li><li><p>快速恢复</p><p>每收到一个重复的ACK拥塞窗口增加1MSS，如果收到新的ACK则拥塞窗口置成阀值</p></li></ul><h2 id="Socket-编程"><a href="#Socket-编程" class="headerlink" title="Socket 编程"></a>Socket 编程</h2><p><img src="http://blog-liuzhangjie.oss-cn-chengdu.aliyuncs.com/img/2023/20230317170611.png" alt="基于 TCP 协议的客户端和服务端工作"> </p><ul><li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li><li>服务端调用 <code>bind</code>，将 socket 绑定在指定的 IP 地址和端口;</li><li>服务端调用 <code>listen</code>，进行监听；</li><li>服务端调用 <code>accept</code>，等待客户端连接；</li><li>客户端调用 <code>connect</code>，向服务端的地址和端口发起连接请求；</li><li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li><li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li><li>客户端断开连接时，会调用 <code>close</code>，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭</li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/02/25/hello-world/"/>
      <url>/2022/02/25/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
